{
  "cells": [
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "bkj8p3r08JZu",
        "outputId": "e8263848-78a2-40cb-f270-cde68bcd073c"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Requirement already satisfied: Sastrawi in /usr/local/lib/python3.7/dist-packages (1.0.1)\n"
          ]
        }
      ],
      "source": [
        "!pip install Sastrawi"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "FYoSjhD52jCI"
      },
      "source": [
        "# Import Libraries"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "VGiP4GJK2Ih9",
        "outputId": "8a8faa6d-2012-48c9-bdf9-5c21c34e7775"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[nltk_data] Downloading package punkt to /root/nltk_data...\n",
            "[nltk_data]   Package punkt is already up-to-date!\n",
            "Done\n"
          ]
        }
      ],
      "source": [
        "import re\n",
        "import matplotlib.pyplot as plt\n",
        "import string\n",
        "from nltk.corpus import stopwords\n",
        "import nltk\n",
        "from nltk.corpus import wordnet\n",
        "from nltk.stem import WordNetLemmatizer\n",
        "from nltk.tokenize.treebank import TreebankWordDetokenizer\n",
        "from collections import Counter\n",
        "from wordcloud import WordCloud\n",
        "from nltk.corpus import stopwords\n",
        "import nltk\n",
        "nltk.download('punkt')\n",
        "from gensim.utils import simple_preprocess\n",
        "from nltk.corpus import stopwords\n",
        "import gensim\n",
        "from sklearn.model_selection import train_test_split\n",
        "import spacy\n",
        "import pickle\n",
        "import warnings\n",
        "warnings.filterwarnings('ignore')\n",
        "import seaborn as sns\n",
        "from sklearn.metrics import confusion_matrix\n",
        "import matplotlib.pyplot as plt \n",
        "import tensorflow as tf\n",
        "import keras\n",
        "import numpy as np\n",
        "import pandas as pd\n",
        "import string\n",
        "\n",
        "\n",
        "from nltk.tokenize import word_tokenize\n",
        "from Sastrawi.StopWordRemover.StopWordRemoverFactory import StopWordRemoverFactory\n",
        "from Sastrawi.Stemmer.StemmerFactory import StemmerFactory \n",
        "print('Done')"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "y4PSoMrB2mtx"
      },
      "source": [
        "# Data Import"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "4jjupEBD2Kte"
      },
      "outputs": [],
      "source": [
        "data = pd.read_csv('dataset_tokopedia.csv')"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "kuf5Q14q3gPo"
      },
      "source": [
        "# Data Preprocessing and Data Cleaning"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 896
        },
        "id": "cF89Xkfn3lqs",
        "outputId": "16e24a28-fae0-4a6b-c36c-549e7d872bd0"
      },
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/html": [
              "\n",
              "  <div id=\"df-63098bef-885e-4dff-a002-d85650f5440e\">\n",
              "    <div class=\"colab-df-container\">\n",
              "      <div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>Unnamed: 0</th>\n",
              "      <th>text</th>\n",
              "      <th>rating</th>\n",
              "      <th>category</th>\n",
              "      <th>product_name</th>\n",
              "      <th>product_id</th>\n",
              "      <th>sold</th>\n",
              "      <th>shop_id</th>\n",
              "      <th>product_url</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>95</td>\n",
              "      <td>barang yg dikirim tidak sesuai pesanan</td>\n",
              "      <td>1</td>\n",
              "      <td>pertukangan</td>\n",
              "      <td>Isi Staples Tembak 8 mm best guard</td>\n",
              "      <td>133507638</td>\n",
              "      <td>545</td>\n",
              "      <td>1461393</td>\n",
              "      <td>https://www.tokopedia.com/timurjaya46/isi-stap...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>117</td>\n",
              "      <td>Php, bilang isi ada diseskripsi pas dipesen be...</td>\n",
              "      <td>1</td>\n",
              "      <td>pertukangan</td>\n",
              "      <td>steples tembak / staples tembak kenmaster PROM...</td>\n",
              "      <td>88842566</td>\n",
              "      <td>45</td>\n",
              "      <td>1102298</td>\n",
              "      <td>https://www.tokopedia.com/cahayabelawa/steples...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>188</td>\n",
              "      <td>Beli staples gak jual isinya... hanya sekali p...</td>\n",
              "      <td>1</td>\n",
              "      <td>pertukangan</td>\n",
              "      <td>Staple Gun / Staples Tembak / Staples Jok / He...</td>\n",
              "      <td>209226141</td>\n",
              "      <td>171</td>\n",
              "      <td>580197</td>\n",
              "      <td>https://www.tokopedia.com/hmhhardware/staple-g...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>255</td>\n",
              "      <td>Sebaiknya kalau mau ngirim barang...diperiksa ...</td>\n",
              "      <td>1</td>\n",
              "      <td>pertukangan</td>\n",
              "      <td>Isi / Refill Staples / Stapler Tembak / Steple...</td>\n",
              "      <td>55221811</td>\n",
              "      <td>67</td>\n",
              "      <td>452241</td>\n",
              "      <td>https://www.tokopedia.com/cgrtools/isi-refill-...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>826</td>\n",
              "      <td>barang datang cacat ,gak bisa di gunakan \\nhar...</td>\n",
              "      <td>1</td>\n",
              "      <td>pertukangan</td>\n",
              "      <td>Staple Staples Steples Gun Tembak Kenmaster Gu...</td>\n",
              "      <td>213653744</td>\n",
              "      <td>122</td>\n",
              "      <td>1461393</td>\n",
              "      <td>https://www.tokopedia.com/timurjaya46/staple-s...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>5</th>\n",
              "      <td>865</td>\n",
              "      <td>Kecewa baru dipakey isiya kluar sampai 2 3 bua...</td>\n",
              "      <td>1</td>\n",
              "      <td>pertukangan</td>\n",
              "      <td>STAPLE GUN MOLLAR 3 WAY TACKER - STAPLES JOK T...</td>\n",
              "      <td>288306960</td>\n",
              "      <td>148</td>\n",
              "      <td>1477109</td>\n",
              "      <td>https://www.tokopedia.com/juraganperkakas/stap...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>6</th>\n",
              "      <td>1015</td>\n",
              "      <td>Hasil staples tidak rapat pada bidang, mungkin...</td>\n",
              "      <td>1</td>\n",
              "      <td>pertukangan</td>\n",
              "      <td>Staples Gun Tacker Mollar 3 in 1 / Staple Jok ...</td>\n",
              "      <td>221298191</td>\n",
              "      <td>408</td>\n",
              "      <td>1114588</td>\n",
              "      <td>https://www.tokopedia.com/indahjayatools/stapl...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>7</th>\n",
              "      <td>1074</td>\n",
              "      <td>Barangnya rusak..kecewa berat</td>\n",
              "      <td>1</td>\n",
              "      <td>pertukangan</td>\n",
              "      <td>STAPLE GUN SERBAGUNA MOLLAR STAPLES TEMBAK BON...</td>\n",
              "      <td>225536821</td>\n",
              "      <td>85</td>\n",
              "      <td>537844</td>\n",
              "      <td>https://www.tokopedia.com/samudrabauteknik/sta...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>8</th>\n",
              "      <td>1244</td>\n",
              "      <td>Beli 5 tdk bs dipakai semua</td>\n",
              "      <td>1</td>\n",
              "      <td>pertukangan</td>\n",
              "      <td>Staple/Stapel/Straples/Staples Nail &amp;amp; paku...</td>\n",
              "      <td>78773158</td>\n",
              "      <td>207</td>\n",
              "      <td>1371033</td>\n",
              "      <td>https://www.tokopedia.com/totalteknik/staplest...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>9</th>\n",
              "      <td>1246</td>\n",
              "      <td>Straples nya gk bs dipake,  udh dicoba berkali...</td>\n",
              "      <td>1</td>\n",
              "      <td>pertukangan</td>\n",
              "      <td>Staple/Stapel/Straples/Staples Nail &amp;amp; paku...</td>\n",
              "      <td>78773158</td>\n",
              "      <td>207</td>\n",
              "      <td>1371033</td>\n",
              "      <td>https://www.tokopedia.com/totalteknik/staplest...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>10</th>\n",
              "      <td>1433</td>\n",
              "      <td>gagal.........................</td>\n",
              "      <td>1</td>\n",
              "      <td>pertukangan</td>\n",
              "      <td>Hekter Tembak / Staples / Guntacker</td>\n",
              "      <td>11888855</td>\n",
              "      <td>175</td>\n",
              "      <td>88752</td>\n",
              "      <td>https://www.tokopedia.com/suryanusantara/hekte...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>11</th>\n",
              "      <td>1468</td>\n",
              "      <td>ggdjkkjfkghfyhdjhugfvkchzndfjhadfafhjkkiutff</td>\n",
              "      <td>1</td>\n",
              "      <td>pertukangan</td>\n",
              "      <td>Hekter Tembak / Staples / Guntacker</td>\n",
              "      <td>11888855</td>\n",
              "      <td>175</td>\n",
              "      <td>88752</td>\n",
              "      <td>https://www.tokopedia.com/suryanusantara/hekte...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>12</th>\n",
              "      <td>1549</td>\n",
              "      <td>SELLER TIDAK KOMUNIKATIF, NIATNYA PAKE INSTANT...</td>\n",
              "      <td>1</td>\n",
              "      <td>pertukangan</td>\n",
              "      <td>3 in 1 Staple Stapel Straples Staples Streples...</td>\n",
              "      <td>17741002</td>\n",
              "      <td>126</td>\n",
              "      <td>154386</td>\n",
              "      <td>https://www.tokopedia.com/e-shop2wheel/3-in-1-...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>13</th>\n",
              "      <td>1769</td>\n",
              "      <td>barang ada yg gak sesuai sama buset lama bange...</td>\n",
              "      <td>1</td>\n",
              "      <td>pertukangan</td>\n",
              "      <td>Staple Gun 3 Way Homaster Heavy Duty / Staples...</td>\n",
              "      <td>19337557</td>\n",
              "      <td>417</td>\n",
              "      <td>580197</td>\n",
              "      <td>https://www.tokopedia.com/hmhhardware/staple-g...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>14</th>\n",
              "      <td>1843</td>\n",
              "      <td>Tidak recommended, kaki tidak bisa masuk, sepa...</td>\n",
              "      <td>1</td>\n",
              "      <td>fashion</td>\n",
              "      <td>Sepatu Sneakers Adidas Swift Run Harian Runnin...</td>\n",
              "      <td>363833137</td>\n",
              "      <td>69</td>\n",
              "      <td>52614</td>\n",
              "      <td>https://www.tokopedia.com/ojarr/sepatu-sneaker...</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>\n",
              "      <button class=\"colab-df-convert\" onclick=\"convertToInteractive('df-63098bef-885e-4dff-a002-d85650f5440e')\"\n",
              "              title=\"Convert this dataframe to an interactive table.\"\n",
              "              style=\"display:none;\">\n",
              "        \n",
              "  <svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\"viewBox=\"0 0 24 24\"\n",
              "       width=\"24px\">\n",
              "    <path d=\"M0 0h24v24H0V0z\" fill=\"none\"/>\n",
              "    <path d=\"M18.56 5.44l.94 2.06.94-2.06 2.06-.94-2.06-.94-.94-2.06-.94 2.06-2.06.94zm-11 1L8.5 8.5l.94-2.06 2.06-.94-2.06-.94L8.5 2.5l-.94 2.06-2.06.94zm10 10l.94 2.06.94-2.06 2.06-.94-2.06-.94-.94-2.06-.94 2.06-2.06.94z\"/><path d=\"M17.41 7.96l-1.37-1.37c-.4-.4-.92-.59-1.43-.59-.52 0-1.04.2-1.43.59L10.3 9.45l-7.72 7.72c-.78.78-.78 2.05 0 2.83L4 21.41c.39.39.9.59 1.41.59.51 0 1.02-.2 1.41-.59l7.78-7.78 2.81-2.81c.8-.78.8-2.07 0-2.86zM5.41 20L4 18.59l7.72-7.72 1.47 1.35L5.41 20z\"/>\n",
              "  </svg>\n",
              "      </button>\n",
              "      \n",
              "  <style>\n",
              "    .colab-df-container {\n",
              "      display:flex;\n",
              "      flex-wrap:wrap;\n",
              "      gap: 12px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert {\n",
              "      background-color: #E8F0FE;\n",
              "      border: none;\n",
              "      border-radius: 50%;\n",
              "      cursor: pointer;\n",
              "      display: none;\n",
              "      fill: #1967D2;\n",
              "      height: 32px;\n",
              "      padding: 0 0 0 0;\n",
              "      width: 32px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert:hover {\n",
              "      background-color: #E2EBFA;\n",
              "      box-shadow: 0px 1px 2px rgba(60, 64, 67, 0.3), 0px 1px 3px 1px rgba(60, 64, 67, 0.15);\n",
              "      fill: #174EA6;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert {\n",
              "      background-color: #3B4455;\n",
              "      fill: #D2E3FC;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert:hover {\n",
              "      background-color: #434B5C;\n",
              "      box-shadow: 0px 1px 3px 1px rgba(0, 0, 0, 0.15);\n",
              "      filter: drop-shadow(0px 1px 2px rgba(0, 0, 0, 0.3));\n",
              "      fill: #FFFFFF;\n",
              "    }\n",
              "  </style>\n",
              "\n",
              "      <script>\n",
              "        const buttonEl =\n",
              "          document.querySelector('#df-63098bef-885e-4dff-a002-d85650f5440e button.colab-df-convert');\n",
              "        buttonEl.style.display =\n",
              "          google.colab.kernel.accessAllowed ? 'block' : 'none';\n",
              "\n",
              "        async function convertToInteractive(key) {\n",
              "          const element = document.querySelector('#df-63098bef-885e-4dff-a002-d85650f5440e');\n",
              "          const dataTable =\n",
              "            await google.colab.kernel.invokeFunction('convertToInteractive',\n",
              "                                                     [key], {});\n",
              "          if (!dataTable) return;\n",
              "\n",
              "          const docLinkHtml = 'Like what you see? Visit the ' +\n",
              "            '<a target=\"_blank\" href=https://colab.research.google.com/notebooks/data_table.ipynb>data table notebook</a>'\n",
              "            + ' to learn more about interactive tables.';\n",
              "          element.innerHTML = '';\n",
              "          dataTable['output_type'] = 'display_data';\n",
              "          await google.colab.output.renderOutput(dataTable, element);\n",
              "          const docLink = document.createElement('div');\n",
              "          docLink.innerHTML = docLinkHtml;\n",
              "          element.appendChild(docLink);\n",
              "        }\n",
              "      </script>\n",
              "    </div>\n",
              "  </div>\n",
              "  "
            ],
            "text/plain": [
              "    Unnamed: 0  ...                                        product_url\n",
              "0           95  ...  https://www.tokopedia.com/timurjaya46/isi-stap...\n",
              "1          117  ...  https://www.tokopedia.com/cahayabelawa/steples...\n",
              "2          188  ...  https://www.tokopedia.com/hmhhardware/staple-g...\n",
              "3          255  ...  https://www.tokopedia.com/cgrtools/isi-refill-...\n",
              "4          826  ...  https://www.tokopedia.com/timurjaya46/staple-s...\n",
              "5          865  ...  https://www.tokopedia.com/juraganperkakas/stap...\n",
              "6         1015  ...  https://www.tokopedia.com/indahjayatools/stapl...\n",
              "7         1074  ...  https://www.tokopedia.com/samudrabauteknik/sta...\n",
              "8         1244  ...  https://www.tokopedia.com/totalteknik/staplest...\n",
              "9         1246  ...  https://www.tokopedia.com/totalteknik/staplest...\n",
              "10        1433  ...  https://www.tokopedia.com/suryanusantara/hekte...\n",
              "11        1468  ...  https://www.tokopedia.com/suryanusantara/hekte...\n",
              "12        1549  ...  https://www.tokopedia.com/e-shop2wheel/3-in-1-...\n",
              "13        1769  ...  https://www.tokopedia.com/hmhhardware/staple-g...\n",
              "14        1843  ...  https://www.tokopedia.com/ojarr/sepatu-sneaker...\n",
              "\n",
              "[15 rows x 9 columns]"
            ]
          },
          "metadata": {},
          "execution_count": 99
        }
      ],
      "source": [
        "data.head(15)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "xHvwstyh3_3B",
        "outputId": "e26978eb-3bf0-4390-e72b-8e13debbf68b"
      },
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "14"
            ]
          },
          "metadata": {},
          "execution_count": 100
        }
      ],
      "source": [
        "#Mengecek jumlah data null\n",
        "len(data) - len(data.dropna())"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "FF0PqDuv4D_C",
        "outputId": "f1e7da62-094f-4162-bc7b-2dd4d3bd6a48"
      },
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "40607"
            ]
          },
          "metadata": {},
          "execution_count": 101
        }
      ],
      "source": [
        "#Mengecek jumlah data\n",
        "len(data)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 476
        },
        "id": "Wp7acVdc4R0W",
        "outputId": "5d034696-4392-4c62-bd70-e0be9abb66a1"
      },
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/html": [
              "\n",
              "  <div id=\"df-e8f9b815-2f71-491a-ae2c-0df9423ec9f4\">\n",
              "    <div class=\"colab-df-container\">\n",
              "      <div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>Unnamed: 0</th>\n",
              "      <th>text</th>\n",
              "      <th>rating</th>\n",
              "      <th>category</th>\n",
              "      <th>product_name</th>\n",
              "      <th>product_id</th>\n",
              "      <th>sold</th>\n",
              "      <th>shop_id</th>\n",
              "      <th>product_url</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>95</td>\n",
              "      <td>barang yg dikirim tidak sesuai pesanan</td>\n",
              "      <td>1</td>\n",
              "      <td>pertukangan</td>\n",
              "      <td>Isi Staples Tembak 8 mm best guard</td>\n",
              "      <td>133507638</td>\n",
              "      <td>545</td>\n",
              "      <td>1461393</td>\n",
              "      <td>https://www.tokopedia.com/timurjaya46/isi-stap...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>117</td>\n",
              "      <td>Php, bilang isi ada diseskripsi pas dipesen be...</td>\n",
              "      <td>1</td>\n",
              "      <td>pertukangan</td>\n",
              "      <td>steples tembak / staples tembak kenmaster PROM...</td>\n",
              "      <td>88842566</td>\n",
              "      <td>45</td>\n",
              "      <td>1102298</td>\n",
              "      <td>https://www.tokopedia.com/cahayabelawa/steples...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>188</td>\n",
              "      <td>Beli staples gak jual isinya... hanya sekali p...</td>\n",
              "      <td>1</td>\n",
              "      <td>pertukangan</td>\n",
              "      <td>Staple Gun / Staples Tembak / Staples Jok / He...</td>\n",
              "      <td>209226141</td>\n",
              "      <td>171</td>\n",
              "      <td>580197</td>\n",
              "      <td>https://www.tokopedia.com/hmhhardware/staple-g...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>255</td>\n",
              "      <td>Sebaiknya kalau mau ngirim barang...diperiksa ...</td>\n",
              "      <td>1</td>\n",
              "      <td>pertukangan</td>\n",
              "      <td>Isi / Refill Staples / Stapler Tembak / Steple...</td>\n",
              "      <td>55221811</td>\n",
              "      <td>67</td>\n",
              "      <td>452241</td>\n",
              "      <td>https://www.tokopedia.com/cgrtools/isi-refill-...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>826</td>\n",
              "      <td>barang datang cacat ,gak bisa di gunakan \\nhar...</td>\n",
              "      <td>1</td>\n",
              "      <td>pertukangan</td>\n",
              "      <td>Staple Staples Steples Gun Tembak Kenmaster Gu...</td>\n",
              "      <td>213653744</td>\n",
              "      <td>122</td>\n",
              "      <td>1461393</td>\n",
              "      <td>https://www.tokopedia.com/timurjaya46/staple-s...</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>\n",
              "      <button class=\"colab-df-convert\" onclick=\"convertToInteractive('df-e8f9b815-2f71-491a-ae2c-0df9423ec9f4')\"\n",
              "              title=\"Convert this dataframe to an interactive table.\"\n",
              "              style=\"display:none;\">\n",
              "        \n",
              "  <svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\"viewBox=\"0 0 24 24\"\n",
              "       width=\"24px\">\n",
              "    <path d=\"M0 0h24v24H0V0z\" fill=\"none\"/>\n",
              "    <path d=\"M18.56 5.44l.94 2.06.94-2.06 2.06-.94-2.06-.94-.94-2.06-.94 2.06-2.06.94zm-11 1L8.5 8.5l.94-2.06 2.06-.94-2.06-.94L8.5 2.5l-.94 2.06-2.06.94zm10 10l.94 2.06.94-2.06 2.06-.94-2.06-.94-.94-2.06-.94 2.06-2.06.94z\"/><path d=\"M17.41 7.96l-1.37-1.37c-.4-.4-.92-.59-1.43-.59-.52 0-1.04.2-1.43.59L10.3 9.45l-7.72 7.72c-.78.78-.78 2.05 0 2.83L4 21.41c.39.39.9.59 1.41.59.51 0 1.02-.2 1.41-.59l7.78-7.78 2.81-2.81c.8-.78.8-2.07 0-2.86zM5.41 20L4 18.59l7.72-7.72 1.47 1.35L5.41 20z\"/>\n",
              "  </svg>\n",
              "      </button>\n",
              "      \n",
              "  <style>\n",
              "    .colab-df-container {\n",
              "      display:flex;\n",
              "      flex-wrap:wrap;\n",
              "      gap: 12px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert {\n",
              "      background-color: #E8F0FE;\n",
              "      border: none;\n",
              "      border-radius: 50%;\n",
              "      cursor: pointer;\n",
              "      display: none;\n",
              "      fill: #1967D2;\n",
              "      height: 32px;\n",
              "      padding: 0 0 0 0;\n",
              "      width: 32px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert:hover {\n",
              "      background-color: #E2EBFA;\n",
              "      box-shadow: 0px 1px 2px rgba(60, 64, 67, 0.3), 0px 1px 3px 1px rgba(60, 64, 67, 0.15);\n",
              "      fill: #174EA6;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert {\n",
              "      background-color: #3B4455;\n",
              "      fill: #D2E3FC;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert:hover {\n",
              "      background-color: #434B5C;\n",
              "      box-shadow: 0px 1px 3px 1px rgba(0, 0, 0, 0.15);\n",
              "      filter: drop-shadow(0px 1px 2px rgba(0, 0, 0, 0.3));\n",
              "      fill: #FFFFFF;\n",
              "    }\n",
              "  </style>\n",
              "\n",
              "      <script>\n",
              "        const buttonEl =\n",
              "          document.querySelector('#df-e8f9b815-2f71-491a-ae2c-0df9423ec9f4 button.colab-df-convert');\n",
              "        buttonEl.style.display =\n",
              "          google.colab.kernel.accessAllowed ? 'block' : 'none';\n",
              "\n",
              "        async function convertToInteractive(key) {\n",
              "          const element = document.querySelector('#df-e8f9b815-2f71-491a-ae2c-0df9423ec9f4');\n",
              "          const dataTable =\n",
              "            await google.colab.kernel.invokeFunction('convertToInteractive',\n",
              "                                                     [key], {});\n",
              "          if (!dataTable) return;\n",
              "\n",
              "          const docLinkHtml = 'Like what you see? Visit the ' +\n",
              "            '<a target=\"_blank\" href=https://colab.research.google.com/notebooks/data_table.ipynb>data table notebook</a>'\n",
              "            + ' to learn more about interactive tables.';\n",
              "          element.innerHTML = '';\n",
              "          dataTable['output_type'] = 'display_data';\n",
              "          await google.colab.output.renderOutput(dataTable, element);\n",
              "          const docLink = document.createElement('div');\n",
              "          docLink.innerHTML = docLinkHtml;\n",
              "          element.appendChild(docLink);\n",
              "        }\n",
              "      </script>\n",
              "    </div>\n",
              "  </div>\n",
              "  "
            ],
            "text/plain": [
              "   Unnamed: 0  ...                                        product_url\n",
              "0          95  ...  https://www.tokopedia.com/timurjaya46/isi-stap...\n",
              "1         117  ...  https://www.tokopedia.com/cahayabelawa/steples...\n",
              "2         188  ...  https://www.tokopedia.com/hmhhardware/staple-g...\n",
              "3         255  ...  https://www.tokopedia.com/cgrtools/isi-refill-...\n",
              "4         826  ...  https://www.tokopedia.com/timurjaya46/staple-s...\n",
              "\n",
              "[5 rows x 9 columns]"
            ]
          },
          "metadata": {},
          "execution_count": 102
        }
      ],
      "source": [
        "#Membuang data null\n",
        "data = data.dropna()\n",
        "len(data)\n",
        "data.head()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "a0UbxPGD4fk5"
      },
      "outputs": [],
      "source": [
        "#Drop column yang tidak digunakan\n",
        "data = data.drop (['Unnamed: 0','category','product_id','sold', 'shop_id', 'product_url'], axis = 1)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "mtnXkXMi7Obk"
      },
      "outputs": [],
      "source": [
        "#Menambahkan kolom sentimen sesuai rating review\n",
        "def sentiment(n):\n",
        "    if n <= 3:\n",
        "      return 0\n",
        "    else:\n",
        "      return 1\n",
        "data['sentiment'] = data['rating'].apply(sentiment)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 143
        },
        "id": "60J4Hku3GucC",
        "outputId": "78799987-cad8-4b1a-8bfa-9774f1d77090"
      },
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/html": [
              "\n",
              "  <div id=\"df-b89af9b0-7939-4580-99e4-02f4e3c79ac8\">\n",
              "    <div class=\"colab-df-container\">\n",
              "      <div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>text</th>\n",
              "      <th>rating</th>\n",
              "      <th>product_name</th>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>sentiment</th>\n",
              "      <th></th>\n",
              "      <th></th>\n",
              "      <th></th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>2750</td>\n",
              "      <td>2750</td>\n",
              "      <td>2750</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>37843</td>\n",
              "      <td>37843</td>\n",
              "      <td>37843</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>\n",
              "      <button class=\"colab-df-convert\" onclick=\"convertToInteractive('df-b89af9b0-7939-4580-99e4-02f4e3c79ac8')\"\n",
              "              title=\"Convert this dataframe to an interactive table.\"\n",
              "              style=\"display:none;\">\n",
              "        \n",
              "  <svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\"viewBox=\"0 0 24 24\"\n",
              "       width=\"24px\">\n",
              "    <path d=\"M0 0h24v24H0V0z\" fill=\"none\"/>\n",
              "    <path d=\"M18.56 5.44l.94 2.06.94-2.06 2.06-.94-2.06-.94-.94-2.06-.94 2.06-2.06.94zm-11 1L8.5 8.5l.94-2.06 2.06-.94-2.06-.94L8.5 2.5l-.94 2.06-2.06.94zm10 10l.94 2.06.94-2.06 2.06-.94-2.06-.94-.94-2.06-.94 2.06-2.06.94z\"/><path d=\"M17.41 7.96l-1.37-1.37c-.4-.4-.92-.59-1.43-.59-.52 0-1.04.2-1.43.59L10.3 9.45l-7.72 7.72c-.78.78-.78 2.05 0 2.83L4 21.41c.39.39.9.59 1.41.59.51 0 1.02-.2 1.41-.59l7.78-7.78 2.81-2.81c.8-.78.8-2.07 0-2.86zM5.41 20L4 18.59l7.72-7.72 1.47 1.35L5.41 20z\"/>\n",
              "  </svg>\n",
              "      </button>\n",
              "      \n",
              "  <style>\n",
              "    .colab-df-container {\n",
              "      display:flex;\n",
              "      flex-wrap:wrap;\n",
              "      gap: 12px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert {\n",
              "      background-color: #E8F0FE;\n",
              "      border: none;\n",
              "      border-radius: 50%;\n",
              "      cursor: pointer;\n",
              "      display: none;\n",
              "      fill: #1967D2;\n",
              "      height: 32px;\n",
              "      padding: 0 0 0 0;\n",
              "      width: 32px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert:hover {\n",
              "      background-color: #E2EBFA;\n",
              "      box-shadow: 0px 1px 2px rgba(60, 64, 67, 0.3), 0px 1px 3px 1px rgba(60, 64, 67, 0.15);\n",
              "      fill: #174EA6;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert {\n",
              "      background-color: #3B4455;\n",
              "      fill: #D2E3FC;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert:hover {\n",
              "      background-color: #434B5C;\n",
              "      box-shadow: 0px 1px 3px 1px rgba(0, 0, 0, 0.15);\n",
              "      filter: drop-shadow(0px 1px 2px rgba(0, 0, 0, 0.3));\n",
              "      fill: #FFFFFF;\n",
              "    }\n",
              "  </style>\n",
              "\n",
              "      <script>\n",
              "        const buttonEl =\n",
              "          document.querySelector('#df-b89af9b0-7939-4580-99e4-02f4e3c79ac8 button.colab-df-convert');\n",
              "        buttonEl.style.display =\n",
              "          google.colab.kernel.accessAllowed ? 'block' : 'none';\n",
              "\n",
              "        async function convertToInteractive(key) {\n",
              "          const element = document.querySelector('#df-b89af9b0-7939-4580-99e4-02f4e3c79ac8');\n",
              "          const dataTable =\n",
              "            await google.colab.kernel.invokeFunction('convertToInteractive',\n",
              "                                                     [key], {});\n",
              "          if (!dataTable) return;\n",
              "\n",
              "          const docLinkHtml = 'Like what you see? Visit the ' +\n",
              "            '<a target=\"_blank\" href=https://colab.research.google.com/notebooks/data_table.ipynb>data table notebook</a>'\n",
              "            + ' to learn more about interactive tables.';\n",
              "          element.innerHTML = '';\n",
              "          dataTable['output_type'] = 'display_data';\n",
              "          await google.colab.output.renderOutput(dataTable, element);\n",
              "          const docLink = document.createElement('div');\n",
              "          docLink.innerHTML = docLinkHtml;\n",
              "          element.appendChild(docLink);\n",
              "        }\n",
              "      </script>\n",
              "    </div>\n",
              "  </div>\n",
              "  "
            ],
            "text/plain": [
              "            text  rating  product_name\n",
              "sentiment                             \n",
              "0           2750    2750          2750\n",
              "1          37843   37843         37843"
            ]
          },
          "metadata": {},
          "execution_count": 106
        }
      ],
      "source": [
        "data.groupby(by='sentiment').count()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "Gb3RIcWbLbU4"
      },
      "outputs": [],
      "source": [
        "data = data.iloc[:6000,:]"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "data.groupby(by='sentiment').count()"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 143
        },
        "id": "9uHr6eXXeiyo",
        "outputId": "2232ae08-9d35-4aa2-874f-ebdfc22811b9"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/html": [
              "\n",
              "  <div id=\"df-c026aa70-013c-4798-8d3b-a9e0ee42a8b6\">\n",
              "    <div class=\"colab-df-container\">\n",
              "      <div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>text</th>\n",
              "      <th>rating</th>\n",
              "      <th>product_name</th>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>sentiment</th>\n",
              "      <th></th>\n",
              "      <th></th>\n",
              "      <th></th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>2750</td>\n",
              "      <td>2750</td>\n",
              "      <td>2750</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>3250</td>\n",
              "      <td>3250</td>\n",
              "      <td>3250</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>\n",
              "      <button class=\"colab-df-convert\" onclick=\"convertToInteractive('df-c026aa70-013c-4798-8d3b-a9e0ee42a8b6')\"\n",
              "              title=\"Convert this dataframe to an interactive table.\"\n",
              "              style=\"display:none;\">\n",
              "        \n",
              "  <svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\"viewBox=\"0 0 24 24\"\n",
              "       width=\"24px\">\n",
              "    <path d=\"M0 0h24v24H0V0z\" fill=\"none\"/>\n",
              "    <path d=\"M18.56 5.44l.94 2.06.94-2.06 2.06-.94-2.06-.94-.94-2.06-.94 2.06-2.06.94zm-11 1L8.5 8.5l.94-2.06 2.06-.94-2.06-.94L8.5 2.5l-.94 2.06-2.06.94zm10 10l.94 2.06.94-2.06 2.06-.94-2.06-.94-.94-2.06-.94 2.06-2.06.94z\"/><path d=\"M17.41 7.96l-1.37-1.37c-.4-.4-.92-.59-1.43-.59-.52 0-1.04.2-1.43.59L10.3 9.45l-7.72 7.72c-.78.78-.78 2.05 0 2.83L4 21.41c.39.39.9.59 1.41.59.51 0 1.02-.2 1.41-.59l7.78-7.78 2.81-2.81c.8-.78.8-2.07 0-2.86zM5.41 20L4 18.59l7.72-7.72 1.47 1.35L5.41 20z\"/>\n",
              "  </svg>\n",
              "      </button>\n",
              "      \n",
              "  <style>\n",
              "    .colab-df-container {\n",
              "      display:flex;\n",
              "      flex-wrap:wrap;\n",
              "      gap: 12px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert {\n",
              "      background-color: #E8F0FE;\n",
              "      border: none;\n",
              "      border-radius: 50%;\n",
              "      cursor: pointer;\n",
              "      display: none;\n",
              "      fill: #1967D2;\n",
              "      height: 32px;\n",
              "      padding: 0 0 0 0;\n",
              "      width: 32px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert:hover {\n",
              "      background-color: #E2EBFA;\n",
              "      box-shadow: 0px 1px 2px rgba(60, 64, 67, 0.3), 0px 1px 3px 1px rgba(60, 64, 67, 0.15);\n",
              "      fill: #174EA6;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert {\n",
              "      background-color: #3B4455;\n",
              "      fill: #D2E3FC;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert:hover {\n",
              "      background-color: #434B5C;\n",
              "      box-shadow: 0px 1px 3px 1px rgba(0, 0, 0, 0.15);\n",
              "      filter: drop-shadow(0px 1px 2px rgba(0, 0, 0, 0.3));\n",
              "      fill: #FFFFFF;\n",
              "    }\n",
              "  </style>\n",
              "\n",
              "      <script>\n",
              "        const buttonEl =\n",
              "          document.querySelector('#df-c026aa70-013c-4798-8d3b-a9e0ee42a8b6 button.colab-df-convert');\n",
              "        buttonEl.style.display =\n",
              "          google.colab.kernel.accessAllowed ? 'block' : 'none';\n",
              "\n",
              "        async function convertToInteractive(key) {\n",
              "          const element = document.querySelector('#df-c026aa70-013c-4798-8d3b-a9e0ee42a8b6');\n",
              "          const dataTable =\n",
              "            await google.colab.kernel.invokeFunction('convertToInteractive',\n",
              "                                                     [key], {});\n",
              "          if (!dataTable) return;\n",
              "\n",
              "          const docLinkHtml = 'Like what you see? Visit the ' +\n",
              "            '<a target=\"_blank\" href=https://colab.research.google.com/notebooks/data_table.ipynb>data table notebook</a>'\n",
              "            + ' to learn more about interactive tables.';\n",
              "          element.innerHTML = '';\n",
              "          dataTable['output_type'] = 'display_data';\n",
              "          await google.colab.output.renderOutput(dataTable, element);\n",
              "          const docLink = document.createElement('div');\n",
              "          docLink.innerHTML = docLinkHtml;\n",
              "          element.appendChild(docLink);\n",
              "        }\n",
              "      </script>\n",
              "    </div>\n",
              "  </div>\n",
              "  "
            ],
            "text/plain": [
              "           text  rating  product_name\n",
              "sentiment                            \n",
              "0          2750    2750          2750\n",
              "1          3250    3250          3250"
            ]
          },
          "metadata": {},
          "execution_count": 108
        }
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "pud4ud_Q6djF",
        "outputId": "8a5f6e24-45a9-41d3-8a9f-4d805f68278a"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "0                   barang yg dikirim tidak sesuai pesanan\n",
            "1        Php, bilang isi ada diseskripsi pas dipesen be...\n",
            "2        Beli staples gak jual isinya... hanya sekali p...\n",
            "3        Sebaiknya kalau mau ngirim barang...diperiksa ...\n",
            "4        barang datang cacat ,gak bisa di gunakan \\nhar...\n",
            "                               ...                        \n",
            "40602      Barang sudah kami terima ya gan.terimakasih gan\n",
            "40603        bagus barangnya.lolos quality cek.mantep dech\n",
            "40604             thaaaanksss barang bagus cepat sampai :)\n",
            "40605     fast respon dan barang sesuai dgn yg di iklankan\n",
            "40606    Mantab, pengiriman sangat cepat, barang pking ...\n",
            "Name: text, Length: 40593, dtype: object\n"
          ]
        }
      ],
      "source": [
        "print(data['text'])"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "SGqVkSL1-Brn"
      },
      "outputs": [],
      "source": [
        "data['review'] = data['text'].str.lower()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "ktG_ZqRS-Fgx"
      },
      "outputs": [],
      "source": [
        "def remove_special_character(text):\n",
        "    text = text.replace('\\\\t',\" \").replace('\\\\n',\" \").replace('\\\\u',\" \").replace('\\\\',\"\")\n",
        "    text = text.encode('ascii', 'replace').decode('ascii')\n",
        "    text = ' '.join(re.sub(\"([@#][A-Za-z0-9]+)|(\\w+:\\/\\/\\S+)\",\" \", text).split())\n",
        "    return text.replace(\"http://\", \" \").replace(\"https://\", \" \")\n",
        "data['review'] = data['review'].apply(remove_special_character)   "
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "JYi3BHsW-N3v"
      },
      "outputs": [],
      "source": [
        "def remove_number(text):\n",
        "    return  re.sub(r\"\\d+\", \"\", text)\n",
        "\n",
        "\n",
        "data['review'] = data['review'].apply(remove_number)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "_EG_eKIM-QLS"
      },
      "outputs": [],
      "source": [
        "def remove_punctuation(text):\n",
        "    return text.translate(str.maketrans(\"\",\"\",string.punctuation))\n",
        "\n",
        "data['review'] = data['review'].apply(remove_punctuation)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "NKTjYX6x-Sjl"
      },
      "outputs": [],
      "source": [
        "def remove_whitespace(text):\n",
        "    txt = text.strip()\n",
        "    return re.sub('\\s+',' ',txt)\n",
        "data['review'] = data['review'].apply(remove_whitespace)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "QW-1wySC_InJ"
      },
      "outputs": [],
      "source": [
        "def remove_singl_char(text):\n",
        "    return re.sub(r\"\\b[a-zA-Z]\\b\", \"\", text)\n",
        "data['review'] = data['review'].apply(remove_singl_char)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "exkajF-s-Sld"
      },
      "outputs": [],
      "source": [
        "factory = StopWordRemoverFactory()\n",
        "stopword = factory.create_stop_word_remover()\n",
        "\n",
        "def stopwords_removal(text):\n",
        "  return stopword.remove(text)\n",
        "\n",
        "data['review'] = data['review'].apply(stopwords_removal) "
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "cm20V_aoD2OB",
        "outputId": "6bab5d84-00fe-4729-90d7-70b170272b4e"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "0                        barang yg dikirim sesuai pesanan\n",
            "1       php bilang isi diseskripsi pas dipesen berbeda...\n",
            "2         beli staples gak jual isinya sekali pake ckckck\n",
            "3       sebaiknya kalau mau ngirim barangdiperiksa dul...\n",
            "4       barang datang cacat gak gunakan harusnya sblum...\n",
            "                              ...                        \n",
            "5998     usefull pemakaian standard cukup baik dikelasnya\n",
            "5999                  terimakasih maju jaya aktifkan jaya\n",
            "6000                     barang nyampe gan sesuai pesanan\n",
            "6001                            bagus aja brg pabrik juga\n",
            "6002                                good barang berfungsi\n",
            "Name: review, Length: 6000, dtype: object\n"
          ]
        }
      ],
      "source": [
        "print(data['review'])"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "esKy6LFjJszg"
      },
      "outputs": [],
      "source": [
        "#Mengubah series panda to list\n",
        "temp = []\n",
        "data_to_list = data['review'].values.tolist()\n",
        "for i in range(len(data_to_list)):\n",
        "    temp.append(data_to_list[i])"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "hjOcCb10Js8h"
      },
      "outputs": [],
      "source": [
        "data_list = np.array(data_to_list)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "YaVunyaVKdMM"
      },
      "outputs": [],
      "source": [
        "#Label Encoding\n",
        "labels = np.array(data['sentiment'])\n",
        "y = []\n",
        "for i in range(len(labels)):\n",
        "    if labels[i] == 0:\n",
        "        y.append(0)\n",
        "    if labels[i] == 1:\n",
        "        y.append(1)\n",
        "\n",
        "y = np.array(y)\n",
        "labels = tf.keras.utils.to_categorical(y, 3, dtype=\"float32\")\n",
        "del y"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "YtzflM5GKwUG",
        "outputId": "830cfde3-8eed-4c31-e56f-e5c35e84664a"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[[   0    0    0 ...   30    2   14]\n",
            " [   0    0    0 ...  394   22  171]\n",
            " [   0    0    0 ...   82   96 1832]\n",
            " ...\n",
            " [   0    0    0 ...   13    2   14]\n",
            " [   0    0    0 ...   76 1738  330]\n",
            " [   0    0    0 ...   84    1   48]]\n"
          ]
        }
      ],
      "source": [
        "#Data Tokenizing\n",
        "from keras.models import Sequential\n",
        "from keras import layers\n",
        "from tensorflow.keras.optimizers import RMSprop,Adam\n",
        "from keras.preprocessing.text import Tokenizer\n",
        "from keras.preprocessing.sequence import pad_sequences\n",
        "from keras import regularizers\n",
        "from keras import backend as K\n",
        "from keras.callbacks import ModelCheckpoint\n",
        "max_words = 5000\n",
        "max_len = 200\n",
        "\n",
        "tokenizer = Tokenizer(num_words=max_words)\n",
        "tokenizer.fit_on_texts(data_list)\n",
        "sequences = tokenizer.texts_to_sequences(data_list)\n",
        "review = pad_sequences(sequences, maxlen=max_len)\n",
        "print(review)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "2LPD0qblK8QT",
        "outputId": "d0685329-b016-49ec-be1b-4fc02d515b8d"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[[1. 0. 0.]\n",
            " [1. 0. 0.]\n",
            " [1. 0. 0.]\n",
            " ...\n",
            " [0. 1. 0.]\n",
            " [0. 1. 0.]\n",
            " [0. 1. 0.]]\n"
          ]
        }
      ],
      "source": [
        "print(labels)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "aETHfjKWK8Sd",
        "outputId": "b83d4547-08bb-4774-fd41-a19f7db5f48e"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "4500 1500 4500 1500\n"
          ]
        }
      ],
      "source": [
        "#Data Train Test Split\n",
        "X_train, X_test, y_train, y_test = train_test_split(review,labels, random_state=0)\n",
        "print (len(X_train),len(X_test),len(y_train),len(y_test))"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "-29jSiUQ9rM-"
      },
      "source": [
        "# Model 1-1"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "ksugSWtyK9gK",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "6b5e858b-92f4-4021-c6d0-a63133e9333c"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "WARNING:tensorflow:`period` argument is deprecated. Please use `save_freq` to specify the frequency in number of batches seen.\n",
            "Epoch 1/50\n",
            "141/141 [==============================] - ETA: 0s - loss: 0.8026 - accuracy: 0.5267\n",
            "Epoch 00001: val_loss improved from inf to 0.70823, saving model to model1.hdf5\n",
            "141/141 [==============================] - 23s 148ms/step - loss: 0.8026 - accuracy: 0.5267 - val_loss: 0.7082 - val_accuracy: 0.6073\n",
            "Epoch 2/50\n",
            "141/141 [==============================] - ETA: 0s - loss: 0.6839 - accuracy: 0.6364\n",
            "Epoch 00002: val_loss improved from 0.70823 to 0.64631, saving model to model1.hdf5\n",
            "141/141 [==============================] - 20s 144ms/step - loss: 0.6839 - accuracy: 0.6364 - val_loss: 0.6463 - val_accuracy: 0.6767\n",
            "Epoch 3/50\n",
            "141/141 [==============================] - ETA: 0s - loss: 0.6306 - accuracy: 0.6731\n",
            "Epoch 00003: val_loss improved from 0.64631 to 0.60682, saving model to model1.hdf5\n",
            "141/141 [==============================] - 10s 68ms/step - loss: 0.6306 - accuracy: 0.6731 - val_loss: 0.6068 - val_accuracy: 0.6940\n",
            "Epoch 4/50\n",
            "141/141 [==============================] - ETA: 0s - loss: 0.5956 - accuracy: 0.6931\n",
            "Epoch 00004: val_loss improved from 0.60682 to 0.58618, saving model to model1.hdf5\n",
            "141/141 [==============================] - 10s 68ms/step - loss: 0.5956 - accuracy: 0.6931 - val_loss: 0.5862 - val_accuracy: 0.7007\n",
            "Epoch 5/50\n",
            "141/141 [==============================] - ETA: 0s - loss: 0.5685 - accuracy: 0.7100\n",
            "Epoch 00005: val_loss improved from 0.58618 to 0.57195, saving model to model1.hdf5\n",
            "141/141 [==============================] - 9s 67ms/step - loss: 0.5685 - accuracy: 0.7100 - val_loss: 0.5720 - val_accuracy: 0.7173\n",
            "Epoch 6/50\n",
            "141/141 [==============================] - ETA: 0s - loss: 0.5440 - accuracy: 0.7369\n",
            "Epoch 00006: val_loss improved from 0.57195 to 0.56553, saving model to model1.hdf5\n",
            "141/141 [==============================] - 10s 69ms/step - loss: 0.5440 - accuracy: 0.7369 - val_loss: 0.5655 - val_accuracy: 0.7247\n",
            "Epoch 7/50\n",
            "141/141 [==============================] - ETA: 0s - loss: 0.5282 - accuracy: 0.7456\n",
            "Epoch 00007: val_loss improved from 0.56553 to 0.56339, saving model to model1.hdf5\n",
            "141/141 [==============================] - 10s 68ms/step - loss: 0.5282 - accuracy: 0.7456 - val_loss: 0.5634 - val_accuracy: 0.7140\n",
            "Epoch 8/50\n",
            "141/141 [==============================] - ETA: 0s - loss: 0.5169 - accuracy: 0.7518\n",
            "Epoch 00008: val_loss improved from 0.56339 to 0.56309, saving model to model1.hdf5\n",
            "141/141 [==============================] - 10s 69ms/step - loss: 0.5169 - accuracy: 0.7518 - val_loss: 0.5631 - val_accuracy: 0.7147\n",
            "Epoch 9/50\n",
            "141/141 [==============================] - ETA: 0s - loss: 0.5068 - accuracy: 0.7569\n",
            "Epoch 00009: val_loss improved from 0.56309 to 0.56264, saving model to model1.hdf5\n",
            "141/141 [==============================] - 10s 69ms/step - loss: 0.5068 - accuracy: 0.7569 - val_loss: 0.5626 - val_accuracy: 0.7213\n",
            "Epoch 10/50\n",
            "141/141 [==============================] - ETA: 0s - loss: 0.4929 - accuracy: 0.7682\n",
            "Epoch 00010: val_loss did not improve from 0.56264\n",
            "141/141 [==============================] - 10s 73ms/step - loss: 0.4929 - accuracy: 0.7682 - val_loss: 0.5644 - val_accuracy: 0.7233\n",
            "Epoch 11/50\n",
            "141/141 [==============================] - ETA: 0s - loss: 0.4901 - accuracy: 0.7684\n",
            "Epoch 00011: val_loss did not improve from 0.56264\n",
            "141/141 [==============================] - 10s 69ms/step - loss: 0.4901 - accuracy: 0.7684 - val_loss: 0.5642 - val_accuracy: 0.7260\n",
            "Epoch 12/50\n",
            "141/141 [==============================] - ETA: 0s - loss: 0.4749 - accuracy: 0.7776\n",
            "Epoch 00012: val_loss did not improve from 0.56264\n",
            "141/141 [==============================] - 10s 69ms/step - loss: 0.4749 - accuracy: 0.7776 - val_loss: 0.5719 - val_accuracy: 0.7393\n",
            "Epoch 13/50\n",
            "141/141 [==============================] - ETA: 0s - loss: 0.4729 - accuracy: 0.7827\n",
            "Epoch 00013: val_loss did not improve from 0.56264\n",
            "141/141 [==============================] - 10s 73ms/step - loss: 0.4729 - accuracy: 0.7827 - val_loss: 0.5688 - val_accuracy: 0.7340\n",
            "Epoch 14/50\n",
            "141/141 [==============================] - ETA: 0s - loss: 0.4645 - accuracy: 0.7856\n",
            "Epoch 00014: val_loss did not improve from 0.56264\n",
            "141/141 [==============================] - 10s 70ms/step - loss: 0.4645 - accuracy: 0.7856 - val_loss: 0.5690 - val_accuracy: 0.7253\n",
            "Epoch 15/50\n",
            "141/141 [==============================] - ETA: 0s - loss: 0.4535 - accuracy: 0.7904\n",
            "Epoch 00015: val_loss did not improve from 0.56264\n",
            "141/141 [==============================] - 10s 69ms/step - loss: 0.4535 - accuracy: 0.7904 - val_loss: 0.5741 - val_accuracy: 0.7240\n",
            "Epoch 16/50\n",
            "141/141 [==============================] - ETA: 0s - loss: 0.4499 - accuracy: 0.7918\n",
            "Epoch 00016: val_loss did not improve from 0.56264\n",
            "141/141 [==============================] - 10s 71ms/step - loss: 0.4499 - accuracy: 0.7918 - val_loss: 0.5790 - val_accuracy: 0.7280\n",
            "Epoch 17/50\n",
            "141/141 [==============================] - ETA: 0s - loss: 0.4415 - accuracy: 0.8016\n",
            "Epoch 00017: val_loss did not improve from 0.56264\n",
            "141/141 [==============================] - 10s 69ms/step - loss: 0.4415 - accuracy: 0.8016 - val_loss: 0.5807 - val_accuracy: 0.7293\n",
            "Epoch 18/50\n",
            "141/141 [==============================] - ETA: 0s - loss: 0.4384 - accuracy: 0.8018\n",
            "Epoch 00018: val_loss did not improve from 0.56264\n",
            "141/141 [==============================] - 11s 75ms/step - loss: 0.4384 - accuracy: 0.8018 - val_loss: 0.5829 - val_accuracy: 0.7247\n",
            "Epoch 19/50\n",
            "141/141 [==============================] - ETA: 0s - loss: 0.4378 - accuracy: 0.8033\n",
            "Epoch 00019: val_loss did not improve from 0.56264\n",
            "141/141 [==============================] - 10s 68ms/step - loss: 0.4378 - accuracy: 0.8033 - val_loss: 0.5890 - val_accuracy: 0.7213\n",
            "Epoch 20/50\n",
            "141/141 [==============================] - ETA: 0s - loss: 0.4313 - accuracy: 0.8062\n",
            "Epoch 00020: val_loss did not improve from 0.56264\n",
            "141/141 [==============================] - 9s 67ms/step - loss: 0.4313 - accuracy: 0.8062 - val_loss: 0.5878 - val_accuracy: 0.7293\n",
            "Epoch 21/50\n",
            "141/141 [==============================] - ETA: 0s - loss: 0.4235 - accuracy: 0.8093\n",
            "Epoch 00021: val_loss did not improve from 0.56264\n",
            "141/141 [==============================] - 9s 67ms/step - loss: 0.4235 - accuracy: 0.8093 - val_loss: 0.5934 - val_accuracy: 0.7293\n",
            "Epoch 22/50\n",
            "141/141 [==============================] - ETA: 0s - loss: 0.4193 - accuracy: 0.8133\n",
            "Epoch 00022: val_loss did not improve from 0.56264\n",
            "141/141 [==============================] - 10s 68ms/step - loss: 0.4193 - accuracy: 0.8133 - val_loss: 0.5948 - val_accuracy: 0.7260\n",
            "Epoch 23/50\n",
            "141/141 [==============================] - ETA: 0s - loss: 0.4172 - accuracy: 0.8189\n",
            "Epoch 00023: val_loss did not improve from 0.56264\n",
            "141/141 [==============================] - 10s 69ms/step - loss: 0.4172 - accuracy: 0.8189 - val_loss: 0.5972 - val_accuracy: 0.7260\n",
            "Epoch 24/50\n",
            "141/141 [==============================] - ETA: 0s - loss: 0.4098 - accuracy: 0.8191\n",
            "Epoch 00024: val_loss did not improve from 0.56264\n",
            "141/141 [==============================] - 10s 71ms/step - loss: 0.4098 - accuracy: 0.8191 - val_loss: 0.6004 - val_accuracy: 0.7233\n",
            "Epoch 25/50\n",
            "141/141 [==============================] - ETA: 0s - loss: 0.4071 - accuracy: 0.8220\n",
            "Epoch 00025: val_loss did not improve from 0.56264\n",
            "141/141 [==============================] - 9s 67ms/step - loss: 0.4071 - accuracy: 0.8220 - val_loss: 0.6069 - val_accuracy: 0.7167\n",
            "Epoch 26/50\n",
            "141/141 [==============================] - ETA: 0s - loss: 0.4039 - accuracy: 0.8189\n",
            "Epoch 00026: val_loss did not improve from 0.56264\n",
            "141/141 [==============================] - 9s 67ms/step - loss: 0.4039 - accuracy: 0.8189 - val_loss: 0.6073 - val_accuracy: 0.7160\n",
            "Epoch 27/50\n",
            "141/141 [==============================] - ETA: 0s - loss: 0.3993 - accuracy: 0.8276\n",
            "Epoch 00027: val_loss did not improve from 0.56264\n",
            "141/141 [==============================] - 10s 68ms/step - loss: 0.3993 - accuracy: 0.8276 - val_loss: 0.6108 - val_accuracy: 0.7187\n",
            "Epoch 28/50\n",
            "141/141 [==============================] - ETA: 0s - loss: 0.3974 - accuracy: 0.8236\n",
            "Epoch 00028: val_loss did not improve from 0.56264\n",
            "141/141 [==============================] - 9s 67ms/step - loss: 0.3974 - accuracy: 0.8236 - val_loss: 0.6172 - val_accuracy: 0.7213\n",
            "Epoch 29/50\n",
            "141/141 [==============================] - ETA: 0s - loss: 0.3963 - accuracy: 0.8253\n",
            "Epoch 00029: val_loss did not improve from 0.56264\n",
            "141/141 [==============================] - 9s 67ms/step - loss: 0.3963 - accuracy: 0.8253 - val_loss: 0.6147 - val_accuracy: 0.7167\n",
            "Epoch 30/50\n",
            "141/141 [==============================] - ETA: 0s - loss: 0.3866 - accuracy: 0.8327\n",
            "Epoch 00030: val_loss did not improve from 0.56264\n",
            "141/141 [==============================] - 10s 72ms/step - loss: 0.3866 - accuracy: 0.8327 - val_loss: 0.6230 - val_accuracy: 0.7187\n",
            "Epoch 31/50\n",
            "141/141 [==============================] - ETA: 0s - loss: 0.3895 - accuracy: 0.8329\n",
            "Epoch 00031: val_loss did not improve from 0.56264\n",
            "141/141 [==============================] - 9s 67ms/step - loss: 0.3895 - accuracy: 0.8329 - val_loss: 0.6224 - val_accuracy: 0.7200\n",
            "Epoch 32/50\n",
            "141/141 [==============================] - ETA: 0s - loss: 0.3876 - accuracy: 0.8262\n",
            "Epoch 00032: val_loss did not improve from 0.56264\n",
            "141/141 [==============================] - 9s 67ms/step - loss: 0.3876 - accuracy: 0.8262 - val_loss: 0.6357 - val_accuracy: 0.7127\n",
            "Epoch 33/50\n",
            "141/141 [==============================] - ETA: 0s - loss: 0.3820 - accuracy: 0.8362\n",
            "Epoch 00033: val_loss did not improve from 0.56264\n",
            "141/141 [==============================] - 9s 67ms/step - loss: 0.3820 - accuracy: 0.8362 - val_loss: 0.6299 - val_accuracy: 0.7180\n",
            "Epoch 34/50\n",
            "141/141 [==============================] - ETA: 0s - loss: 0.3810 - accuracy: 0.8413\n",
            "Epoch 00034: val_loss did not improve from 0.56264\n",
            "141/141 [==============================] - 10s 68ms/step - loss: 0.3810 - accuracy: 0.8413 - val_loss: 0.6362 - val_accuracy: 0.7153\n",
            "Epoch 35/50\n",
            "141/141 [==============================] - ETA: 0s - loss: 0.3759 - accuracy: 0.8384\n",
            "Epoch 00035: val_loss did not improve from 0.56264\n",
            "141/141 [==============================] - 10s 72ms/step - loss: 0.3759 - accuracy: 0.8384 - val_loss: 0.6422 - val_accuracy: 0.7100\n",
            "Epoch 36/50\n",
            "141/141 [==============================] - ETA: 0s - loss: 0.3727 - accuracy: 0.8420\n",
            "Epoch 00036: val_loss did not improve from 0.56264\n",
            "141/141 [==============================] - 9s 67ms/step - loss: 0.3727 - accuracy: 0.8420 - val_loss: 0.6428 - val_accuracy: 0.7127\n",
            "Epoch 37/50\n",
            "141/141 [==============================] - ETA: 0s - loss: 0.3657 - accuracy: 0.8402\n",
            "Epoch 00037: val_loss did not improve from 0.56264\n",
            "141/141 [==============================] - 9s 67ms/step - loss: 0.3657 - accuracy: 0.8402 - val_loss: 0.6446 - val_accuracy: 0.7153\n",
            "Epoch 38/50\n",
            "141/141 [==============================] - ETA: 0s - loss: 0.3673 - accuracy: 0.8413\n",
            "Epoch 00038: val_loss did not improve from 0.56264\n",
            "141/141 [==============================] - 9s 67ms/step - loss: 0.3673 - accuracy: 0.8413 - val_loss: 0.6461 - val_accuracy: 0.7167\n",
            "Epoch 39/50\n",
            "141/141 [==============================] - ETA: 0s - loss: 0.3651 - accuracy: 0.8436\n",
            "Epoch 00039: val_loss did not improve from 0.56264\n",
            "141/141 [==============================] - 9s 67ms/step - loss: 0.3651 - accuracy: 0.8436 - val_loss: 0.6641 - val_accuracy: 0.7093\n",
            "Epoch 40/50\n",
            "141/141 [==============================] - ETA: 0s - loss: 0.3676 - accuracy: 0.8420\n",
            "Epoch 00040: val_loss did not improve from 0.56264\n",
            "141/141 [==============================] - 9s 67ms/step - loss: 0.3676 - accuracy: 0.8420 - val_loss: 0.6507 - val_accuracy: 0.7147\n",
            "Epoch 41/50\n",
            "141/141 [==============================] - ETA: 0s - loss: 0.3614 - accuracy: 0.8476\n",
            "Epoch 00041: val_loss did not improve from 0.56264\n",
            "141/141 [==============================] - 9s 67ms/step - loss: 0.3614 - accuracy: 0.8476 - val_loss: 0.6563 - val_accuracy: 0.7100\n",
            "Epoch 42/50\n",
            "141/141 [==============================] - ETA: 0s - loss: 0.3607 - accuracy: 0.8464\n",
            "Epoch 00042: val_loss did not improve from 0.56264\n",
            "141/141 [==============================] - 9s 66ms/step - loss: 0.3607 - accuracy: 0.8464 - val_loss: 0.6536 - val_accuracy: 0.7100\n",
            "Epoch 43/50\n",
            "141/141 [==============================] - ETA: 0s - loss: 0.3572 - accuracy: 0.8491\n",
            "Epoch 00043: val_loss did not improve from 0.56264\n",
            "141/141 [==============================] - 9s 65ms/step - loss: 0.3572 - accuracy: 0.8491 - val_loss: 0.6579 - val_accuracy: 0.7067\n",
            "Epoch 44/50\n",
            "141/141 [==============================] - ETA: 0s - loss: 0.3554 - accuracy: 0.8522\n",
            "Epoch 00044: val_loss did not improve from 0.56264\n",
            "141/141 [==============================] - 9s 65ms/step - loss: 0.3554 - accuracy: 0.8522 - val_loss: 0.6668 - val_accuracy: 0.7073\n",
            "Epoch 45/50\n",
            "141/141 [==============================] - ETA: 0s - loss: 0.3540 - accuracy: 0.8502\n",
            "Epoch 00045: val_loss did not improve from 0.56264\n",
            "141/141 [==============================] - 9s 65ms/step - loss: 0.3540 - accuracy: 0.8502 - val_loss: 0.6634 - val_accuracy: 0.7047\n",
            "Epoch 46/50\n",
            "141/141 [==============================] - ETA: 0s - loss: 0.3541 - accuracy: 0.8511\n",
            "Epoch 00046: val_loss did not improve from 0.56264\n",
            "141/141 [==============================] - 9s 66ms/step - loss: 0.3541 - accuracy: 0.8511 - val_loss: 0.6718 - val_accuracy: 0.7093\n",
            "Epoch 47/50\n",
            "141/141 [==============================] - ETA: 0s - loss: 0.3509 - accuracy: 0.8529\n",
            "Epoch 00047: val_loss did not improve from 0.56264\n",
            "141/141 [==============================] - 9s 65ms/step - loss: 0.3509 - accuracy: 0.8529 - val_loss: 0.6682 - val_accuracy: 0.7047\n",
            "Epoch 48/50\n",
            "141/141 [==============================] - ETA: 0s - loss: 0.3465 - accuracy: 0.8511\n",
            "Epoch 00048: val_loss did not improve from 0.56264\n",
            "141/141 [==============================] - 9s 66ms/step - loss: 0.3465 - accuracy: 0.8511 - val_loss: 0.6765 - val_accuracy: 0.7087\n",
            "Epoch 49/50\n",
            "141/141 [==============================] - ETA: 0s - loss: 0.3429 - accuracy: 0.8513\n",
            "Epoch 00049: val_loss did not improve from 0.56264\n",
            "141/141 [==============================] - 9s 66ms/step - loss: 0.3429 - accuracy: 0.8513 - val_loss: 0.6738 - val_accuracy: 0.7080\n",
            "Epoch 50/50\n",
            "141/141 [==============================] - ETA: 0s - loss: 0.3369 - accuracy: 0.8576\n",
            "Epoch 00050: val_loss did not improve from 0.56264\n",
            "141/141 [==============================] - 9s 67ms/step - loss: 0.3369 - accuracy: 0.8576 - val_loss: 0.6762 - val_accuracy: 0.7133\n"
          ]
        }
      ],
      "source": [
        "model1 = Sequential()\n",
        "model1.add(layers.Embedding(max_words, 40, input_length=max_len))\n",
        "model1.add(layers.LSTM(5,dropout=0.6))\n",
        "model1.add(layers.Dense(3,activation='softmax'))\n",
        "model1.compile(optimizer='rmsprop',loss='categorical_crossentropy', metrics=['accuracy'])\n",
        "\n",
        "checkpoint1 = ModelCheckpoint(\"model1.hdf5\", monitor='val_loss', verbose=2,save_best_only=True, mode='auto', period=1,save_weights_only=False)\n",
        "history = model1.fit(X_train, y_train, epochs=50,validation_data=(X_test, y_test),callbacks=[checkpoint1])"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "opg8QeFH-oeY",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "2a771703-7867-48c0-a5c8-c35e252d4d9b"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Model: \"sequential_1\"\n",
            "_________________________________________________________________\n",
            " Layer (type)                Output Shape              Param #   \n",
            "=================================================================\n",
            " embedding_1 (Embedding)     (None, 200, 40)           200000    \n",
            "                                                                 \n",
            " lstm_1 (LSTM)               (None, 5)                 920       \n",
            "                                                                 \n",
            " dense_1 (Dense)             (None, 3)                 18        \n",
            "                                                                 \n",
            "=================================================================\n",
            "Total params: 200,938\n",
            "Trainable params: 200,938\n",
            "Non-trainable params: 0\n",
            "_________________________________________________________________\n"
          ]
        }
      ],
      "source": [
        "model1.summary()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "H2Jqf5kJk-w2"
      },
      "outputs": [],
      "source": [
        "best_model_1 = keras.models.load_model(\"model1.hdf5\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "BUkrAJN2LRUG",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "289b90dc-c966-44c8-b892-fe501d4b3a47"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "47/47 - 1s - loss: 0.5626 - accuracy: 0.7213 - 895ms/epoch - 19ms/step\n"
          ]
        }
      ],
      "source": [
        "test_loss, test_acc, = best_model_1.evaluate(X_test, y_test, verbose=2)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "Nxv03J8zgdLR"
      },
      "outputs": [],
      "source": [
        "predictions1 = best_model_1.predict(X_test)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "hgkdtKD6K9kf",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "91f88a18-d0d5-449e-8ed2-5f72a80b6dc4"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[[358 302]\n",
            " [116 724]]\n"
          ]
        }
      ],
      "source": [
        "from sklearn.metrics import confusion_matrix\n",
        "matrix = confusion_matrix(y_test.argmax(axis=1), np.around(predictions1.argmax(axis=1)))\n",
        "print(matrix)  #tn = 398,fp = 262,fn = 147,tp = 693 "
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "from sklearn.metrics import precision_recall_fscore_support as eval"
      ],
      "metadata": {
        "id": "mKI2D1zzRqkQ"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "precision, recall, fscore, support = eval(y_test.argmax(axis=1), predictions1.argmax(axis=1))\n",
        "print('precision (Negative, Positive):', precision)\n",
        "print('recall (Negative, Positive):', recall)\n",
        "print('fscore (Negative, Positive):', fscore)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "TzgahrcaRwRn",
        "outputId": "ad1e99a5-50cb-49c2-d0cb-8ba549f4c517"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "precision (Negative, Positive): [0.75527426 0.70565302]\n",
            "recall (Negative, Positive): [0.54242424 0.86190476]\n",
            "fscore (Negative, Positive): [0.6313933  0.77599143]\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "kyrHYGFFB7lk"
      },
      "source": [
        "# Model 2-1"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "dmki3iLOB7lp",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "0c44b3d6-2612-4455-b310-964052a6b0b0"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "WARNING:tensorflow:`period` argument is deprecated. Please use `save_freq` to specify the frequency in number of batches seen.\n",
            "Epoch 1/50\n",
            "141/141 [==============================] - ETA: 0s - loss: 0.7613 - accuracy: 0.5916\n",
            "Epoch 00001: val_loss improved from inf to 0.64653, saving model to model2.hdf5\n",
            "141/141 [==============================] - 12s 69ms/step - loss: 0.7613 - accuracy: 0.5916 - val_loss: 0.6465 - val_accuracy: 0.6560\n",
            "Epoch 2/50\n",
            "141/141 [==============================] - ETA: 0s - loss: 0.6335 - accuracy: 0.6556\n",
            "Epoch 00002: val_loss improved from 0.64653 to 0.59750, saving model to model2.hdf5\n",
            "141/141 [==============================] - 9s 65ms/step - loss: 0.6335 - accuracy: 0.6556 - val_loss: 0.5975 - val_accuracy: 0.6920\n",
            "Epoch 3/50\n",
            "141/141 [==============================] - ETA: 0s - loss: 0.5886 - accuracy: 0.6947\n",
            "Epoch 00003: val_loss improved from 0.59750 to 0.57768, saving model to model2.hdf5\n",
            "141/141 [==============================] - 9s 65ms/step - loss: 0.5886 - accuracy: 0.6947 - val_loss: 0.5777 - val_accuracy: 0.7153\n",
            "Epoch 4/50\n",
            "141/141 [==============================] - ETA: 0s - loss: 0.5586 - accuracy: 0.7193\n",
            "Epoch 00004: val_loss improved from 0.57768 to 0.55926, saving model to model2.hdf5\n",
            "141/141 [==============================] - 9s 66ms/step - loss: 0.5586 - accuracy: 0.7193 - val_loss: 0.5593 - val_accuracy: 0.7240\n",
            "Epoch 5/50\n",
            "141/141 [==============================] - ETA: 0s - loss: 0.5446 - accuracy: 0.7296\n",
            "Epoch 00005: val_loss improved from 0.55926 to 0.55775, saving model to model2.hdf5\n",
            "141/141 [==============================] - 9s 67ms/step - loss: 0.5446 - accuracy: 0.7296 - val_loss: 0.5578 - val_accuracy: 0.7200\n",
            "Epoch 6/50\n",
            "141/141 [==============================] - ETA: 0s - loss: 0.5297 - accuracy: 0.7384\n",
            "Epoch 00006: val_loss did not improve from 0.55775\n",
            "141/141 [==============================] - 9s 66ms/step - loss: 0.5297 - accuracy: 0.7384 - val_loss: 0.5691 - val_accuracy: 0.7087\n",
            "Epoch 7/50\n",
            "141/141 [==============================] - ETA: 0s - loss: 0.5176 - accuracy: 0.7480\n",
            "Epoch 00007: val_loss did not improve from 0.55775\n",
            "141/141 [==============================] - 9s 66ms/step - loss: 0.5176 - accuracy: 0.7480 - val_loss: 0.5622 - val_accuracy: 0.7173\n",
            "Epoch 8/50\n",
            "141/141 [==============================] - ETA: 0s - loss: 0.5019 - accuracy: 0.7547\n",
            "Epoch 00008: val_loss did not improve from 0.55775\n",
            "141/141 [==============================] - 9s 66ms/step - loss: 0.5019 - accuracy: 0.7547 - val_loss: 0.6108 - val_accuracy: 0.6840\n",
            "Epoch 9/50\n",
            "141/141 [==============================] - ETA: 0s - loss: 0.4963 - accuracy: 0.7631\n",
            "Epoch 00009: val_loss did not improve from 0.55775\n",
            "141/141 [==============================] - 9s 67ms/step - loss: 0.4963 - accuracy: 0.7631 - val_loss: 0.5687 - val_accuracy: 0.7287\n",
            "Epoch 10/50\n",
            "141/141 [==============================] - ETA: 0s - loss: 0.4889 - accuracy: 0.7720\n",
            "Epoch 00010: val_loss did not improve from 0.55775\n",
            "141/141 [==============================] - 9s 67ms/step - loss: 0.4889 - accuracy: 0.7720 - val_loss: 0.5669 - val_accuracy: 0.7247\n",
            "Epoch 11/50\n",
            "141/141 [==============================] - ETA: 0s - loss: 0.4800 - accuracy: 0.7780\n",
            "Epoch 00011: val_loss did not improve from 0.55775\n",
            "141/141 [==============================] - 9s 66ms/step - loss: 0.4800 - accuracy: 0.7780 - val_loss: 0.5681 - val_accuracy: 0.7267\n",
            "Epoch 12/50\n",
            "141/141 [==============================] - ETA: 0s - loss: 0.4724 - accuracy: 0.7802\n",
            "Epoch 00012: val_loss did not improve from 0.55775\n",
            "141/141 [==============================] - 9s 66ms/step - loss: 0.4724 - accuracy: 0.7802 - val_loss: 0.5934 - val_accuracy: 0.7133\n",
            "Epoch 13/50\n",
            "141/141 [==============================] - ETA: 0s - loss: 0.4615 - accuracy: 0.7847\n",
            "Epoch 00013: val_loss did not improve from 0.55775\n",
            "141/141 [==============================] - 9s 66ms/step - loss: 0.4615 - accuracy: 0.7847 - val_loss: 0.5791 - val_accuracy: 0.7340\n",
            "Epoch 14/50\n",
            "141/141 [==============================] - ETA: 0s - loss: 0.4582 - accuracy: 0.7896\n",
            "Epoch 00014: val_loss did not improve from 0.55775\n",
            "141/141 [==============================] - 9s 67ms/step - loss: 0.4582 - accuracy: 0.7896 - val_loss: 0.5929 - val_accuracy: 0.7213\n",
            "Epoch 15/50\n",
            "141/141 [==============================] - ETA: 0s - loss: 0.4524 - accuracy: 0.7927\n",
            "Epoch 00015: val_loss did not improve from 0.55775\n",
            "141/141 [==============================] - 9s 66ms/step - loss: 0.4524 - accuracy: 0.7927 - val_loss: 0.5767 - val_accuracy: 0.7320\n",
            "Epoch 16/50\n",
            "141/141 [==============================] - ETA: 0s - loss: 0.4496 - accuracy: 0.7964\n",
            "Epoch 00016: val_loss did not improve from 0.55775\n",
            "141/141 [==============================] - 9s 65ms/step - loss: 0.4496 - accuracy: 0.7964 - val_loss: 0.5786 - val_accuracy: 0.7253\n",
            "Epoch 17/50\n",
            "141/141 [==============================] - ETA: 0s - loss: 0.4386 - accuracy: 0.8042\n",
            "Epoch 00017: val_loss did not improve from 0.55775\n",
            "141/141 [==============================] - 9s 65ms/step - loss: 0.4386 - accuracy: 0.8042 - val_loss: 0.5845 - val_accuracy: 0.7333\n",
            "Epoch 18/50\n",
            "141/141 [==============================] - ETA: 0s - loss: 0.4338 - accuracy: 0.8053\n",
            "Epoch 00018: val_loss did not improve from 0.55775\n",
            "141/141 [==============================] - 9s 65ms/step - loss: 0.4338 - accuracy: 0.8053 - val_loss: 0.5953 - val_accuracy: 0.7267\n",
            "Epoch 19/50\n",
            "141/141 [==============================] - ETA: 0s - loss: 0.4292 - accuracy: 0.8082\n",
            "Epoch 00019: val_loss did not improve from 0.55775\n",
            "141/141 [==============================] - 9s 64ms/step - loss: 0.4292 - accuracy: 0.8082 - val_loss: 0.5940 - val_accuracy: 0.7247\n",
            "Epoch 20/50\n",
            "141/141 [==============================] - ETA: 0s - loss: 0.4203 - accuracy: 0.8076\n",
            "Epoch 00020: val_loss did not improve from 0.55775\n",
            "141/141 [==============================] - 9s 64ms/step - loss: 0.4203 - accuracy: 0.8076 - val_loss: 0.5951 - val_accuracy: 0.7353\n",
            "Epoch 21/50\n",
            "141/141 [==============================] - ETA: 0s - loss: 0.4216 - accuracy: 0.8142\n",
            "Epoch 00021: val_loss did not improve from 0.55775\n",
            "141/141 [==============================] - 9s 65ms/step - loss: 0.4216 - accuracy: 0.8142 - val_loss: 0.5983 - val_accuracy: 0.7300\n",
            "Epoch 22/50\n",
            "141/141 [==============================] - ETA: 0s - loss: 0.4131 - accuracy: 0.8184\n",
            "Epoch 00022: val_loss did not improve from 0.55775\n",
            "141/141 [==============================] - 9s 65ms/step - loss: 0.4131 - accuracy: 0.8184 - val_loss: 0.6051 - val_accuracy: 0.7260\n",
            "Epoch 23/50\n",
            "141/141 [==============================] - ETA: 0s - loss: 0.4135 - accuracy: 0.8202\n",
            "Epoch 00023: val_loss did not improve from 0.55775\n",
            "141/141 [==============================] - 9s 66ms/step - loss: 0.4135 - accuracy: 0.8202 - val_loss: 0.6014 - val_accuracy: 0.7300\n",
            "Epoch 24/50\n",
            "141/141 [==============================] - ETA: 0s - loss: 0.4076 - accuracy: 0.8200\n",
            "Epoch 00024: val_loss did not improve from 0.55775\n",
            "141/141 [==============================] - 9s 66ms/step - loss: 0.4076 - accuracy: 0.8200 - val_loss: 0.6103 - val_accuracy: 0.7247\n",
            "Epoch 25/50\n",
            "141/141 [==============================] - ETA: 0s - loss: 0.4005 - accuracy: 0.8244\n",
            "Epoch 00025: val_loss did not improve from 0.55775\n",
            "141/141 [==============================] - 9s 64ms/step - loss: 0.4005 - accuracy: 0.8244 - val_loss: 0.6203 - val_accuracy: 0.7260\n",
            "Epoch 26/50\n",
            "141/141 [==============================] - ETA: 0s - loss: 0.4019 - accuracy: 0.8267\n",
            "Epoch 00026: val_loss did not improve from 0.55775\n",
            "141/141 [==============================] - 9s 64ms/step - loss: 0.4019 - accuracy: 0.8267 - val_loss: 0.6090 - val_accuracy: 0.7227\n",
            "Epoch 27/50\n",
            "141/141 [==============================] - ETA: 0s - loss: 0.3927 - accuracy: 0.8282\n",
            "Epoch 00027: val_loss did not improve from 0.55775\n",
            "141/141 [==============================] - 9s 65ms/step - loss: 0.3927 - accuracy: 0.8282 - val_loss: 0.6232 - val_accuracy: 0.7233\n",
            "Epoch 28/50\n",
            "141/141 [==============================] - ETA: 0s - loss: 0.3914 - accuracy: 0.8258\n",
            "Epoch 00028: val_loss did not improve from 0.55775\n",
            "141/141 [==============================] - 9s 65ms/step - loss: 0.3914 - accuracy: 0.8258 - val_loss: 0.6215 - val_accuracy: 0.7187\n",
            "Epoch 29/50\n",
            "141/141 [==============================] - ETA: 0s - loss: 0.3880 - accuracy: 0.8278\n",
            "Epoch 00029: val_loss did not improve from 0.55775\n",
            "141/141 [==============================] - 9s 66ms/step - loss: 0.3880 - accuracy: 0.8278 - val_loss: 0.6370 - val_accuracy: 0.7247\n",
            "Epoch 30/50\n",
            "141/141 [==============================] - ETA: 0s - loss: 0.3931 - accuracy: 0.8293\n",
            "Epoch 00030: val_loss did not improve from 0.55775\n",
            "141/141 [==============================] - 9s 65ms/step - loss: 0.3931 - accuracy: 0.8293 - val_loss: 0.6265 - val_accuracy: 0.7227\n",
            "Epoch 31/50\n",
            "141/141 [==============================] - ETA: 0s - loss: 0.3853 - accuracy: 0.8342\n",
            "Epoch 00031: val_loss did not improve from 0.55775\n",
            "141/141 [==============================] - 9s 65ms/step - loss: 0.3853 - accuracy: 0.8342 - val_loss: 0.6378 - val_accuracy: 0.7267\n",
            "Epoch 32/50\n",
            "141/141 [==============================] - ETA: 0s - loss: 0.3801 - accuracy: 0.8338\n",
            "Epoch 00032: val_loss did not improve from 0.55775\n",
            "141/141 [==============================] - 9s 66ms/step - loss: 0.3801 - accuracy: 0.8338 - val_loss: 0.6452 - val_accuracy: 0.7240\n",
            "Epoch 33/50\n",
            "141/141 [==============================] - ETA: 0s - loss: 0.3851 - accuracy: 0.8316\n",
            "Epoch 00033: val_loss did not improve from 0.55775\n",
            "141/141 [==============================] - 9s 66ms/step - loss: 0.3851 - accuracy: 0.8316 - val_loss: 0.6276 - val_accuracy: 0.7207\n",
            "Epoch 34/50\n",
            "141/141 [==============================] - ETA: 0s - loss: 0.3796 - accuracy: 0.8331\n",
            "Epoch 00034: val_loss did not improve from 0.55775\n",
            "141/141 [==============================] - 9s 67ms/step - loss: 0.3796 - accuracy: 0.8331 - val_loss: 0.6243 - val_accuracy: 0.7207\n",
            "Epoch 35/50\n",
            "141/141 [==============================] - ETA: 0s - loss: 0.3727 - accuracy: 0.8384\n",
            "Epoch 00035: val_loss did not improve from 0.55775\n",
            "141/141 [==============================] - 10s 68ms/step - loss: 0.3727 - accuracy: 0.8384 - val_loss: 0.6371 - val_accuracy: 0.7200\n",
            "Epoch 36/50\n",
            "141/141 [==============================] - ETA: 0s - loss: 0.3746 - accuracy: 0.8356\n",
            "Epoch 00036: val_loss did not improve from 0.55775\n",
            "141/141 [==============================] - 9s 67ms/step - loss: 0.3746 - accuracy: 0.8356 - val_loss: 0.6466 - val_accuracy: 0.7180\n",
            "Epoch 37/50\n",
            "141/141 [==============================] - ETA: 0s - loss: 0.3695 - accuracy: 0.8424\n",
            "Epoch 00037: val_loss did not improve from 0.55775\n",
            "141/141 [==============================] - 10s 68ms/step - loss: 0.3695 - accuracy: 0.8424 - val_loss: 0.6423 - val_accuracy: 0.7160\n",
            "Epoch 38/50\n",
            "141/141 [==============================] - ETA: 0s - loss: 0.3656 - accuracy: 0.8442\n",
            "Epoch 00038: val_loss did not improve from 0.55775\n",
            "141/141 [==============================] - 9s 67ms/step - loss: 0.3656 - accuracy: 0.8442 - val_loss: 0.6329 - val_accuracy: 0.7173\n",
            "Epoch 39/50\n",
            "141/141 [==============================] - ETA: 0s - loss: 0.3637 - accuracy: 0.8471\n",
            "Epoch 00039: val_loss did not improve from 0.55775\n",
            "141/141 [==============================] - 9s 66ms/step - loss: 0.3637 - accuracy: 0.8471 - val_loss: 0.6520 - val_accuracy: 0.7100\n",
            "Epoch 40/50\n",
            "141/141 [==============================] - ETA: 0s - loss: 0.3618 - accuracy: 0.8464\n",
            "Epoch 00040: val_loss did not improve from 0.55775\n",
            "141/141 [==============================] - 9s 67ms/step - loss: 0.3618 - accuracy: 0.8464 - val_loss: 0.6642 - val_accuracy: 0.7213\n",
            "Epoch 41/50\n",
            "141/141 [==============================] - ETA: 0s - loss: 0.3674 - accuracy: 0.8411\n",
            "Epoch 00041: val_loss did not improve from 0.55775\n",
            "141/141 [==============================] - 10s 68ms/step - loss: 0.3674 - accuracy: 0.8411 - val_loss: 0.6600 - val_accuracy: 0.7160\n",
            "Epoch 42/50\n",
            "141/141 [==============================] - ETA: 0s - loss: 0.3579 - accuracy: 0.8447\n",
            "Epoch 00042: val_loss did not improve from 0.55775\n",
            "141/141 [==============================] - 10s 67ms/step - loss: 0.3579 - accuracy: 0.8447 - val_loss: 0.6624 - val_accuracy: 0.7093\n",
            "Epoch 43/50\n",
            "141/141 [==============================] - ETA: 0s - loss: 0.3602 - accuracy: 0.8431\n",
            "Epoch 00043: val_loss did not improve from 0.55775\n",
            "141/141 [==============================] - 10s 68ms/step - loss: 0.3602 - accuracy: 0.8431 - val_loss: 0.6583 - val_accuracy: 0.7120\n",
            "Epoch 44/50\n",
            "141/141 [==============================] - ETA: 0s - loss: 0.3545 - accuracy: 0.8436\n",
            "Epoch 00044: val_loss did not improve from 0.55775\n",
            "141/141 [==============================] - 9s 67ms/step - loss: 0.3545 - accuracy: 0.8436 - val_loss: 0.6725 - val_accuracy: 0.7147\n",
            "Epoch 45/50\n",
            "141/141 [==============================] - ETA: 0s - loss: 0.3535 - accuracy: 0.8460\n",
            "Epoch 00045: val_loss did not improve from 0.55775\n",
            "141/141 [==============================] - 9s 66ms/step - loss: 0.3535 - accuracy: 0.8460 - val_loss: 0.6698 - val_accuracy: 0.7173\n",
            "Epoch 46/50\n",
            "141/141 [==============================] - ETA: 0s - loss: 0.3524 - accuracy: 0.8491\n",
            "Epoch 00046: val_loss did not improve from 0.55775\n",
            "141/141 [==============================] - 9s 66ms/step - loss: 0.3524 - accuracy: 0.8491 - val_loss: 0.6720 - val_accuracy: 0.7127\n",
            "Epoch 47/50\n",
            "141/141 [==============================] - ETA: 0s - loss: 0.3503 - accuracy: 0.8498\n",
            "Epoch 00047: val_loss did not improve from 0.55775\n",
            "141/141 [==============================] - 9s 67ms/step - loss: 0.3503 - accuracy: 0.8498 - val_loss: 0.6583 - val_accuracy: 0.7133\n",
            "Epoch 48/50\n",
            "141/141 [==============================] - ETA: 0s - loss: 0.3437 - accuracy: 0.8507\n",
            "Epoch 00048: val_loss did not improve from 0.55775\n",
            "141/141 [==============================] - 10s 69ms/step - loss: 0.3437 - accuracy: 0.8507 - val_loss: 0.6777 - val_accuracy: 0.7147\n",
            "Epoch 49/50\n",
            "141/141 [==============================] - ETA: 0s - loss: 0.3474 - accuracy: 0.8502\n",
            "Epoch 00049: val_loss did not improve from 0.55775\n",
            "141/141 [==============================] - 9s 66ms/step - loss: 0.3474 - accuracy: 0.8502 - val_loss: 0.6716 - val_accuracy: 0.7180\n",
            "Epoch 50/50\n",
            "141/141 [==============================] - ETA: 0s - loss: 0.3438 - accuracy: 0.8533\n",
            "Epoch 00050: val_loss did not improve from 0.55775\n",
            "141/141 [==============================] - 9s 66ms/step - loss: 0.3438 - accuracy: 0.8533 - val_loss: 0.6700 - val_accuracy: 0.7133\n"
          ]
        }
      ],
      "source": [
        "model2 = Sequential()\n",
        "model2.add(layers.Embedding(max_words, 40, input_length=max_len))\n",
        "model2.add(layers.LSTM(10,dropout=0.6))\n",
        "model2.add(layers.Dense(3,activation='softmax'))\n",
        "model2.compile(optimizer='rmsprop',loss='categorical_crossentropy', metrics=['accuracy'])\n",
        "\n",
        "checkpoint2 = ModelCheckpoint(\"model2.hdf5\", monitor='val_loss', verbose=2,save_best_only=True, mode='auto', period=1,save_weights_only=False)\n",
        "history = model2.fit(X_train, y_train, epochs=50,validation_data=(X_test, y_test),callbacks=[checkpoint2])"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "TsqKt49mB7lq",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "969c0713-e967-4da8-f88f-d05c07d6d68f"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Model: \"sequential_2\"\n",
            "_________________________________________________________________\n",
            " Layer (type)                Output Shape              Param #   \n",
            "=================================================================\n",
            " embedding_2 (Embedding)     (None, 200, 40)           200000    \n",
            "                                                                 \n",
            " lstm_2 (LSTM)               (None, 10)                2040      \n",
            "                                                                 \n",
            " dense_2 (Dense)             (None, 3)                 33        \n",
            "                                                                 \n",
            "=================================================================\n",
            "Total params: 202,073\n",
            "Trainable params: 202,073\n",
            "Non-trainable params: 0\n",
            "_________________________________________________________________\n"
          ]
        }
      ],
      "source": [
        "model2.summary()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "G07SAkwOB7lq"
      },
      "outputs": [],
      "source": [
        "best_model_2 = keras.models.load_model(\"model2.hdf5\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "lkFWwmBmB7lq",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "f041f916-baca-4df4-d303-6d1de6a21244"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "47/47 - 1s - loss: 0.5578 - accuracy: 0.7200 - 868ms/epoch - 18ms/step\n"
          ]
        }
      ],
      "source": [
        "test_loss, test_acc = best_model_2.evaluate(X_test, y_test, verbose=2)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "NwvvIIcUB7lq"
      },
      "outputs": [],
      "source": [
        "predictions2 = best_model_2.predict(X_test)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "6a434aba-2dda-41eb-b701-498379870846",
        "id": "J4dYou53fsaU"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[[356 304]\n",
            " [116 724]]\n"
          ]
        }
      ],
      "source": [
        "from sklearn.metrics import confusion_matrix\n",
        "matrix = confusion_matrix(y_test.argmax(axis=1), np.around(predictions2.argmax(axis=1)))\n",
        "print(matrix)  #tn = 398,fp = 262,fn = 147,tp = 693 "
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "from sklearn.metrics import precision_recall_fscore_support as eval"
      ],
      "metadata": {
        "id": "fIx4GWfqfsaZ"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "precision, recall, fscore, support = eval(y_test.argmax(axis=1), predictions2.argmax(axis=1))\n",
        "print('precision (Negative, Positive):', precision)\n",
        "print('recall (Negative, Positive):', recall)\n",
        "print('fscore (Negative, Positive):', fscore)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "7b9c540f-1186-41a6-c979-8c1ceccae7f9",
        "id": "JD9ii8rwfsaZ"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "precision (Negative, Positive): [0.75423729 0.70428016]\n",
            "recall (Negative, Positive): [0.53939394 0.86190476]\n",
            "fscore (Negative, Positive): [0.62897527 0.7751606 ]\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "A5RtX483CbXU"
      },
      "source": [
        "# Model 3-1"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "Zrg5J7wlCbXa",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "6defb561-03e9-44f1-d900-2de8976890d7"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "WARNING:tensorflow:`period` argument is deprecated. Please use `save_freq` to specify the frequency in number of batches seen.\n",
            "Epoch 1/50\n",
            "141/141 [==============================] - ETA: 0s - loss: 0.7256 - accuracy: 0.5593\n",
            "Epoch 00001: val_loss improved from inf to 0.65926, saving model to model3.hdf5\n",
            "141/141 [==============================] - 12s 71ms/step - loss: 0.7256 - accuracy: 0.5593 - val_loss: 0.6593 - val_accuracy: 0.6413\n",
            "Epoch 2/50\n",
            "141/141 [==============================] - ETA: 0s - loss: 0.6304 - accuracy: 0.6607\n",
            "Epoch 00002: val_loss improved from 0.65926 to 0.59811, saving model to model3.hdf5\n",
            "141/141 [==============================] - 10s 68ms/step - loss: 0.6304 - accuracy: 0.6607 - val_loss: 0.5981 - val_accuracy: 0.7027\n",
            "Epoch 3/50\n",
            "141/141 [==============================] - ETA: 0s - loss: 0.5890 - accuracy: 0.6933\n",
            "Epoch 00003: val_loss improved from 0.59811 to 0.57007, saving model to model3.hdf5\n",
            "141/141 [==============================] - 10s 69ms/step - loss: 0.5890 - accuracy: 0.6933 - val_loss: 0.5701 - val_accuracy: 0.7207\n",
            "Epoch 4/50\n",
            "141/141 [==============================] - ETA: 0s - loss: 0.5622 - accuracy: 0.7164\n",
            "Epoch 00004: val_loss improved from 0.57007 to 0.56007, saving model to model3.hdf5\n",
            "141/141 [==============================] - 10s 68ms/step - loss: 0.5622 - accuracy: 0.7164 - val_loss: 0.5601 - val_accuracy: 0.7213\n",
            "Epoch 5/50\n",
            "141/141 [==============================] - ETA: 0s - loss: 0.5368 - accuracy: 0.7371\n",
            "Epoch 00005: val_loss did not improve from 0.56007\n",
            "141/141 [==============================] - 10s 68ms/step - loss: 0.5368 - accuracy: 0.7371 - val_loss: 0.5663 - val_accuracy: 0.7307\n",
            "Epoch 6/50\n",
            "141/141 [==============================] - ETA: 0s - loss: 0.5204 - accuracy: 0.7431\n",
            "Epoch 00006: val_loss did not improve from 0.56007\n",
            "141/141 [==============================] - 10s 69ms/step - loss: 0.5204 - accuracy: 0.7431 - val_loss: 0.5605 - val_accuracy: 0.7267\n",
            "Epoch 7/50\n",
            "141/141 [==============================] - ETA: 0s - loss: 0.5046 - accuracy: 0.7596\n",
            "Epoch 00007: val_loss did not improve from 0.56007\n",
            "141/141 [==============================] - 10s 69ms/step - loss: 0.5046 - accuracy: 0.7596 - val_loss: 0.5675 - val_accuracy: 0.7220\n",
            "Epoch 8/50\n",
            "141/141 [==============================] - ETA: 0s - loss: 0.4962 - accuracy: 0.7600\n",
            "Epoch 00008: val_loss did not improve from 0.56007\n",
            "141/141 [==============================] - 10s 69ms/step - loss: 0.4962 - accuracy: 0.7600 - val_loss: 0.5735 - val_accuracy: 0.7180\n",
            "Epoch 9/50\n",
            "141/141 [==============================] - ETA: 0s - loss: 0.4847 - accuracy: 0.7693\n",
            "Epoch 00009: val_loss did not improve from 0.56007\n",
            "141/141 [==============================] - 10s 70ms/step - loss: 0.4847 - accuracy: 0.7693 - val_loss: 0.5679 - val_accuracy: 0.7300\n",
            "Epoch 10/50\n",
            "141/141 [==============================] - ETA: 0s - loss: 0.4705 - accuracy: 0.7787\n",
            "Epoch 00010: val_loss did not improve from 0.56007\n",
            "141/141 [==============================] - 10s 70ms/step - loss: 0.4705 - accuracy: 0.7787 - val_loss: 0.5841 - val_accuracy: 0.7260\n",
            "Epoch 11/50\n",
            "141/141 [==============================] - ETA: 0s - loss: 0.4621 - accuracy: 0.7847\n",
            "Epoch 00011: val_loss did not improve from 0.56007\n",
            "141/141 [==============================] - 10s 70ms/step - loss: 0.4621 - accuracy: 0.7847 - val_loss: 0.5955 - val_accuracy: 0.7240\n",
            "Epoch 12/50\n",
            "141/141 [==============================] - ETA: 0s - loss: 0.4567 - accuracy: 0.7871\n",
            "Epoch 00012: val_loss did not improve from 0.56007\n",
            "141/141 [==============================] - 10s 69ms/step - loss: 0.4567 - accuracy: 0.7871 - val_loss: 0.5832 - val_accuracy: 0.7287\n",
            "Epoch 13/50\n",
            "141/141 [==============================] - ETA: 0s - loss: 0.4451 - accuracy: 0.7936\n",
            "Epoch 00013: val_loss did not improve from 0.56007\n",
            "141/141 [==============================] - 10s 70ms/step - loss: 0.4451 - accuracy: 0.7936 - val_loss: 0.6012 - val_accuracy: 0.7227\n",
            "Epoch 14/50\n",
            "141/141 [==============================] - ETA: 0s - loss: 0.4427 - accuracy: 0.7989\n",
            "Epoch 00014: val_loss did not improve from 0.56007\n",
            "141/141 [==============================] - 10s 69ms/step - loss: 0.4427 - accuracy: 0.7989 - val_loss: 0.5913 - val_accuracy: 0.7320\n",
            "Epoch 15/50\n",
            "141/141 [==============================] - ETA: 0s - loss: 0.4331 - accuracy: 0.8031\n",
            "Epoch 00015: val_loss did not improve from 0.56007\n",
            "141/141 [==============================] - 10s 70ms/step - loss: 0.4331 - accuracy: 0.8031 - val_loss: 0.5955 - val_accuracy: 0.7227\n",
            "Epoch 16/50\n",
            "141/141 [==============================] - ETA: 0s - loss: 0.4315 - accuracy: 0.8033\n",
            "Epoch 00016: val_loss did not improve from 0.56007\n",
            "141/141 [==============================] - 10s 70ms/step - loss: 0.4315 - accuracy: 0.8033 - val_loss: 0.6052 - val_accuracy: 0.7220\n",
            "Epoch 17/50\n",
            "141/141 [==============================] - ETA: 0s - loss: 0.4234 - accuracy: 0.8100\n",
            "Epoch 00017: val_loss did not improve from 0.56007\n",
            "141/141 [==============================] - 10s 70ms/step - loss: 0.4234 - accuracy: 0.8100 - val_loss: 0.5975 - val_accuracy: 0.7280\n",
            "Epoch 18/50\n",
            "141/141 [==============================] - ETA: 0s - loss: 0.4186 - accuracy: 0.8133\n",
            "Epoch 00018: val_loss did not improve from 0.56007\n",
            "141/141 [==============================] - 10s 70ms/step - loss: 0.4186 - accuracy: 0.8133 - val_loss: 0.6058 - val_accuracy: 0.7267\n",
            "Epoch 19/50\n",
            "141/141 [==============================] - ETA: 0s - loss: 0.4089 - accuracy: 0.8169\n",
            "Epoch 00019: val_loss did not improve from 0.56007\n",
            "141/141 [==============================] - 10s 70ms/step - loss: 0.4089 - accuracy: 0.8169 - val_loss: 0.6226 - val_accuracy: 0.7313\n",
            "Epoch 20/50\n",
            "141/141 [==============================] - ETA: 0s - loss: 0.4098 - accuracy: 0.8178\n",
            "Epoch 00020: val_loss did not improve from 0.56007\n",
            "141/141 [==============================] - 10s 70ms/step - loss: 0.4098 - accuracy: 0.8178 - val_loss: 0.6215 - val_accuracy: 0.7213\n",
            "Epoch 21/50\n",
            "141/141 [==============================] - ETA: 0s - loss: 0.4033 - accuracy: 0.8209\n",
            "Epoch 00021: val_loss did not improve from 0.56007\n",
            "141/141 [==============================] - 10s 69ms/step - loss: 0.4033 - accuracy: 0.8209 - val_loss: 0.6215 - val_accuracy: 0.7273\n",
            "Epoch 22/50\n",
            "141/141 [==============================] - ETA: 0s - loss: 0.4004 - accuracy: 0.8187\n",
            "Epoch 00022: val_loss did not improve from 0.56007\n",
            "141/141 [==============================] - 10s 70ms/step - loss: 0.4004 - accuracy: 0.8187 - val_loss: 0.6288 - val_accuracy: 0.7273\n",
            "Epoch 23/50\n",
            "141/141 [==============================] - ETA: 0s - loss: 0.3917 - accuracy: 0.8238\n",
            "Epoch 00023: val_loss did not improve from 0.56007\n",
            "141/141 [==============================] - 10s 70ms/step - loss: 0.3917 - accuracy: 0.8238 - val_loss: 0.6322 - val_accuracy: 0.7240\n",
            "Epoch 24/50\n",
            "141/141 [==============================] - ETA: 0s - loss: 0.3861 - accuracy: 0.8262\n",
            "Epoch 00024: val_loss did not improve from 0.56007\n",
            "141/141 [==============================] - 10s 70ms/step - loss: 0.3861 - accuracy: 0.8262 - val_loss: 0.6311 - val_accuracy: 0.7260\n",
            "Epoch 25/50\n",
            "141/141 [==============================] - ETA: 0s - loss: 0.3866 - accuracy: 0.8304\n",
            "Epoch 00025: val_loss did not improve from 0.56007\n",
            "141/141 [==============================] - 10s 69ms/step - loss: 0.3866 - accuracy: 0.8304 - val_loss: 0.6411 - val_accuracy: 0.7187\n",
            "Epoch 26/50\n",
            "141/141 [==============================] - ETA: 0s - loss: 0.3818 - accuracy: 0.8382\n",
            "Epoch 00026: val_loss did not improve from 0.56007\n",
            "141/141 [==============================] - 10s 70ms/step - loss: 0.3818 - accuracy: 0.8382 - val_loss: 0.6422 - val_accuracy: 0.7227\n",
            "Epoch 27/50\n",
            "141/141 [==============================] - ETA: 0s - loss: 0.3863 - accuracy: 0.8324\n",
            "Epoch 00027: val_loss did not improve from 0.56007\n",
            "141/141 [==============================] - 10s 70ms/step - loss: 0.3863 - accuracy: 0.8324 - val_loss: 0.6474 - val_accuracy: 0.7180\n",
            "Epoch 28/50\n",
            "141/141 [==============================] - ETA: 0s - loss: 0.3781 - accuracy: 0.8360\n",
            "Epoch 00028: val_loss did not improve from 0.56007\n",
            "141/141 [==============================] - 10s 71ms/step - loss: 0.3781 - accuracy: 0.8360 - val_loss: 0.6410 - val_accuracy: 0.7173\n",
            "Epoch 29/50\n",
            "141/141 [==============================] - ETA: 0s - loss: 0.3735 - accuracy: 0.8398\n",
            "Epoch 00029: val_loss did not improve from 0.56007\n",
            "141/141 [==============================] - 10s 70ms/step - loss: 0.3735 - accuracy: 0.8398 - val_loss: 0.6501 - val_accuracy: 0.7200\n",
            "Epoch 30/50\n",
            "141/141 [==============================] - ETA: 0s - loss: 0.3687 - accuracy: 0.8411\n",
            "Epoch 00030: val_loss did not improve from 0.56007\n",
            "141/141 [==============================] - 10s 70ms/step - loss: 0.3687 - accuracy: 0.8411 - val_loss: 0.6486 - val_accuracy: 0.7220\n",
            "Epoch 31/50\n",
            "141/141 [==============================] - ETA: 0s - loss: 0.3669 - accuracy: 0.8436\n",
            "Epoch 00031: val_loss did not improve from 0.56007\n",
            "141/141 [==============================] - 10s 69ms/step - loss: 0.3669 - accuracy: 0.8436 - val_loss: 0.6487 - val_accuracy: 0.7193\n",
            "Epoch 32/50\n",
            "141/141 [==============================] - ETA: 0s - loss: 0.3669 - accuracy: 0.8407\n",
            "Epoch 00032: val_loss did not improve from 0.56007\n",
            "141/141 [==============================] - 10s 69ms/step - loss: 0.3669 - accuracy: 0.8407 - val_loss: 0.6629 - val_accuracy: 0.7193\n",
            "Epoch 33/50\n",
            "141/141 [==============================] - ETA: 0s - loss: 0.3593 - accuracy: 0.8429\n",
            "Epoch 00033: val_loss did not improve from 0.56007\n",
            "141/141 [==============================] - 10s 70ms/step - loss: 0.3593 - accuracy: 0.8429 - val_loss: 0.6608 - val_accuracy: 0.7127\n",
            "Epoch 34/50\n",
            "141/141 [==============================] - ETA: 0s - loss: 0.3597 - accuracy: 0.8453\n",
            "Epoch 00034: val_loss did not improve from 0.56007\n",
            "141/141 [==============================] - 10s 71ms/step - loss: 0.3597 - accuracy: 0.8453 - val_loss: 0.6594 - val_accuracy: 0.7127\n",
            "Epoch 35/50\n",
            "141/141 [==============================] - ETA: 0s - loss: 0.3528 - accuracy: 0.8509\n",
            "Epoch 00035: val_loss did not improve from 0.56007\n",
            "141/141 [==============================] - 10s 70ms/step - loss: 0.3528 - accuracy: 0.8509 - val_loss: 0.6762 - val_accuracy: 0.7193\n",
            "Epoch 36/50\n",
            "141/141 [==============================] - ETA: 0s - loss: 0.3536 - accuracy: 0.8476\n",
            "Epoch 00036: val_loss did not improve from 0.56007\n",
            "141/141 [==============================] - 10s 70ms/step - loss: 0.3536 - accuracy: 0.8476 - val_loss: 0.6635 - val_accuracy: 0.7200\n",
            "Epoch 37/50\n",
            "141/141 [==============================] - ETA: 0s - loss: 0.3505 - accuracy: 0.8536\n",
            "Epoch 00037: val_loss did not improve from 0.56007\n",
            "141/141 [==============================] - 10s 71ms/step - loss: 0.3505 - accuracy: 0.8536 - val_loss: 0.6706 - val_accuracy: 0.7167\n",
            "Epoch 38/50\n",
            "141/141 [==============================] - ETA: 0s - loss: 0.3389 - accuracy: 0.8544\n",
            "Epoch 00038: val_loss did not improve from 0.56007\n",
            "141/141 [==============================] - 10s 70ms/step - loss: 0.3389 - accuracy: 0.8544 - val_loss: 0.6881 - val_accuracy: 0.7113\n",
            "Epoch 39/50\n",
            "141/141 [==============================] - ETA: 0s - loss: 0.3421 - accuracy: 0.8533\n",
            "Epoch 00039: val_loss did not improve from 0.56007\n",
            "141/141 [==============================] - 10s 69ms/step - loss: 0.3421 - accuracy: 0.8533 - val_loss: 0.6911 - val_accuracy: 0.7060\n",
            "Epoch 40/50\n",
            "141/141 [==============================] - ETA: 0s - loss: 0.3414 - accuracy: 0.8547\n",
            "Epoch 00040: val_loss did not improve from 0.56007\n",
            "141/141 [==============================] - 10s 70ms/step - loss: 0.3414 - accuracy: 0.8547 - val_loss: 0.6952 - val_accuracy: 0.7127\n",
            "Epoch 41/50\n",
            "141/141 [==============================] - ETA: 0s - loss: 0.3430 - accuracy: 0.8531\n",
            "Epoch 00041: val_loss did not improve from 0.56007\n",
            "141/141 [==============================] - 10s 70ms/step - loss: 0.3430 - accuracy: 0.8531 - val_loss: 0.6871 - val_accuracy: 0.7087\n",
            "Epoch 42/50\n",
            "141/141 [==============================] - ETA: 0s - loss: 0.3329 - accuracy: 0.8578\n",
            "Epoch 00042: val_loss did not improve from 0.56007\n",
            "141/141 [==============================] - 10s 70ms/step - loss: 0.3329 - accuracy: 0.8578 - val_loss: 0.6989 - val_accuracy: 0.7127\n",
            "Epoch 43/50\n",
            "141/141 [==============================] - ETA: 0s - loss: 0.3332 - accuracy: 0.8567\n",
            "Epoch 00043: val_loss did not improve from 0.56007\n",
            "141/141 [==============================] - 10s 71ms/step - loss: 0.3332 - accuracy: 0.8567 - val_loss: 0.7056 - val_accuracy: 0.7073\n",
            "Epoch 44/50\n",
            "141/141 [==============================] - ETA: 0s - loss: 0.3375 - accuracy: 0.8531\n",
            "Epoch 00044: val_loss did not improve from 0.56007\n",
            "141/141 [==============================] - 10s 72ms/step - loss: 0.3375 - accuracy: 0.8531 - val_loss: 0.7018 - val_accuracy: 0.7073\n",
            "Epoch 45/50\n",
            "141/141 [==============================] - ETA: 0s - loss: 0.3304 - accuracy: 0.8604\n",
            "Epoch 00045: val_loss did not improve from 0.56007\n",
            "141/141 [==============================] - 10s 70ms/step - loss: 0.3304 - accuracy: 0.8604 - val_loss: 0.7149 - val_accuracy: 0.7180\n",
            "Epoch 46/50\n",
            "141/141 [==============================] - ETA: 0s - loss: 0.3297 - accuracy: 0.8580\n",
            "Epoch 00046: val_loss did not improve from 0.56007\n",
            "141/141 [==============================] - 10s 70ms/step - loss: 0.3297 - accuracy: 0.8580 - val_loss: 0.7218 - val_accuracy: 0.7173\n",
            "Epoch 47/50\n",
            "141/141 [==============================] - ETA: 0s - loss: 0.3262 - accuracy: 0.8662\n",
            "Epoch 00047: val_loss did not improve from 0.56007\n",
            "141/141 [==============================] - 10s 71ms/step - loss: 0.3262 - accuracy: 0.8662 - val_loss: 0.7129 - val_accuracy: 0.7067\n",
            "Epoch 48/50\n",
            "141/141 [==============================] - ETA: 0s - loss: 0.3241 - accuracy: 0.8596\n",
            "Epoch 00048: val_loss did not improve from 0.56007\n",
            "141/141 [==============================] - 10s 70ms/step - loss: 0.3241 - accuracy: 0.8596 - val_loss: 0.7333 - val_accuracy: 0.7080\n",
            "Epoch 49/50\n",
            "141/141 [==============================] - ETA: 0s - loss: 0.3250 - accuracy: 0.8647\n",
            "Epoch 00049: val_loss did not improve from 0.56007\n",
            "141/141 [==============================] - 10s 70ms/step - loss: 0.3250 - accuracy: 0.8647 - val_loss: 0.7035 - val_accuracy: 0.7033\n",
            "Epoch 50/50\n",
            "141/141 [==============================] - ETA: 0s - loss: 0.3204 - accuracy: 0.8622\n",
            "Epoch 00050: val_loss did not improve from 0.56007\n",
            "141/141 [==============================] - 10s 70ms/step - loss: 0.3204 - accuracy: 0.8622 - val_loss: 0.7203 - val_accuracy: 0.7040\n"
          ]
        }
      ],
      "source": [
        "model3 = Sequential()\n",
        "model3.add(layers.Embedding(max_words, 40, input_length=max_len))\n",
        "model3.add(layers.LSTM(15,dropout=0.6))\n",
        "model3.add(layers.Dense(3,activation='softmax'))\n",
        "model3.compile(optimizer='rmsprop',loss='categorical_crossentropy', metrics=['accuracy'])\n",
        "\n",
        "checkpoint3 = ModelCheckpoint(\"model3.hdf5\", monitor='val_loss', verbose=2,save_best_only=True, mode='auto', period=1,save_weights_only=False)\n",
        "history = model3.fit(X_train, y_train, epochs=50,validation_data=(X_test, y_test),callbacks=[checkpoint3])"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "UlDN-pcmCbXa",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "2b0e2116-7ef6-47b0-9c17-6028f7dd87ba"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Model: \"sequential_3\"\n",
            "_________________________________________________________________\n",
            " Layer (type)                Output Shape              Param #   \n",
            "=================================================================\n",
            " embedding_3 (Embedding)     (None, 200, 40)           200000    \n",
            "                                                                 \n",
            " lstm_3 (LSTM)               (None, 15)                3360      \n",
            "                                                                 \n",
            " dense_3 (Dense)             (None, 3)                 48        \n",
            "                                                                 \n",
            "=================================================================\n",
            "Total params: 203,408\n",
            "Trainable params: 203,408\n",
            "Non-trainable params: 0\n",
            "_________________________________________________________________\n"
          ]
        }
      ],
      "source": [
        "model3.summary()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "3IZLNBZrCbXa"
      },
      "outputs": [],
      "source": [
        "best_model_3 = keras.models.load_model(\"model3.hdf5\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "PPhJqOtXCbXa",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "531b5a77-4630-4d34-a841-7bf9b5823c98"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "47/47 - 1s - loss: 0.5601 - accuracy: 0.7213 - 914ms/epoch - 19ms/step\n"
          ]
        }
      ],
      "source": [
        "test_loss, test_acc = best_model_3.evaluate(X_test, y_test, verbose=2)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "dVb_ocPNCbXa"
      },
      "outputs": [],
      "source": [
        "predictions3 = best_model_3.predict(X_test)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "19c68276-ad0f-4788-f8c8-089e8a9dfc0e",
        "id": "FWKA98U3f0EH"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[[369 291]\n",
            " [127 713]]\n"
          ]
        }
      ],
      "source": [
        "from sklearn.metrics import confusion_matrix\n",
        "matrix = confusion_matrix(y_test.argmax(axis=1), np.around(predictions3.argmax(axis=1)))\n",
        "print(matrix)"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "from sklearn.metrics import precision_recall_fscore_support as eval"
      ],
      "metadata": {
        "id": "hTbZozHAf0EH"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "precision, recall, fscore, support = eval(y_test.argmax(axis=1), predictions3.argmax(axis=1))\n",
        "print('precision (Negative, Positive):', precision)\n",
        "print('recall (Negative, Positive):', recall)\n",
        "print('fscore (Negative, Positive):', fscore)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "0d24568d-3e1b-42e5-cfa0-6d6f8bd359b0",
        "id": "_CAuRQNhf0EH"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "precision (Negative, Positive): [0.74395161 0.71015936]\n",
            "recall (Negative, Positive): [0.55909091 0.84880952]\n",
            "fscore (Negative, Positive): [0.6384083  0.77331887]\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "yV5xYqblCcwo"
      },
      "source": [
        "# Model 1-2"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "L2bRQCb4Ccwp",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "b741155b-803a-4c8b-c81e-dd7482720dcf"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "WARNING:tensorflow:`period` argument is deprecated. Please use `save_freq` to specify the frequency in number of batches seen.\n",
            "Epoch 1/50\n",
            "141/141 [==============================] - ETA: 0s - loss: 0.8936 - accuracy: 0.5913\n",
            "Epoch 00001: val_loss improved from inf to 0.72024, saving model to model4.hdf5\n",
            "141/141 [==============================] - 11s 68ms/step - loss: 0.8936 - accuracy: 0.5913 - val_loss: 0.7202 - val_accuracy: 0.6560\n",
            "Epoch 2/50\n",
            "141/141 [==============================] - ETA: 0s - loss: 0.6758 - accuracy: 0.6673\n",
            "Epoch 00002: val_loss improved from 0.72024 to 0.63419, saving model to model4.hdf5\n",
            "141/141 [==============================] - 9s 65ms/step - loss: 0.6758 - accuracy: 0.6673 - val_loss: 0.6342 - val_accuracy: 0.6953\n",
            "Epoch 3/50\n",
            "141/141 [==============================] - ETA: 0s - loss: 0.5859 - accuracy: 0.7309\n",
            "Epoch 00003: val_loss improved from 0.63419 to 0.57849, saving model to model4.hdf5\n",
            "141/141 [==============================] - 9s 65ms/step - loss: 0.5859 - accuracy: 0.7309 - val_loss: 0.5785 - val_accuracy: 0.7313\n",
            "Epoch 4/50\n",
            "141/141 [==============================] - ETA: 0s - loss: 0.5219 - accuracy: 0.7696\n",
            "Epoch 00004: val_loss improved from 0.57849 to 0.57138, saving model to model4.hdf5\n",
            "141/141 [==============================] - 9s 64ms/step - loss: 0.5219 - accuracy: 0.7696 - val_loss: 0.5714 - val_accuracy: 0.7267\n",
            "Epoch 5/50\n",
            "141/141 [==============================] - ETA: 0s - loss: 0.4749 - accuracy: 0.7940\n",
            "Epoch 00005: val_loss improved from 0.57138 to 0.56710, saving model to model4.hdf5\n",
            "141/141 [==============================] - 9s 64ms/step - loss: 0.4749 - accuracy: 0.7940 - val_loss: 0.5671 - val_accuracy: 0.7267\n",
            "Epoch 6/50\n",
            "141/141 [==============================] - ETA: 0s - loss: 0.4310 - accuracy: 0.8149\n",
            "Epoch 00006: val_loss did not improve from 0.56710\n",
            "141/141 [==============================] - 9s 64ms/step - loss: 0.4310 - accuracy: 0.8149 - val_loss: 0.5798 - val_accuracy: 0.7273\n",
            "Epoch 7/50\n",
            "141/141 [==============================] - ETA: 0s - loss: 0.3959 - accuracy: 0.8367\n",
            "Epoch 00007: val_loss did not improve from 0.56710\n",
            "141/141 [==============================] - 10s 67ms/step - loss: 0.3959 - accuracy: 0.8367 - val_loss: 0.6117 - val_accuracy: 0.7160\n",
            "Epoch 8/50\n",
            "141/141 [==============================] - ETA: 0s - loss: 0.3760 - accuracy: 0.8362\n",
            "Epoch 00008: val_loss did not improve from 0.56710\n",
            "141/141 [==============================] - 10s 70ms/step - loss: 0.3760 - accuracy: 0.8362 - val_loss: 0.6254 - val_accuracy: 0.7087\n",
            "Epoch 9/50\n",
            "141/141 [==============================] - ETA: 0s - loss: 0.3511 - accuracy: 0.8549\n",
            "Epoch 00009: val_loss did not improve from 0.56710\n",
            "141/141 [==============================] - 11s 76ms/step - loss: 0.3511 - accuracy: 0.8549 - val_loss: 0.6369 - val_accuracy: 0.7133\n",
            "Epoch 10/50\n",
            "141/141 [==============================] - ETA: 0s - loss: 0.3297 - accuracy: 0.8609\n",
            "Epoch 00010: val_loss did not improve from 0.56710\n",
            "141/141 [==============================] - 10s 72ms/step - loss: 0.3297 - accuracy: 0.8609 - val_loss: 0.6648 - val_accuracy: 0.6980\n",
            "Epoch 11/50\n",
            "141/141 [==============================] - ETA: 0s - loss: 0.3202 - accuracy: 0.8640\n",
            "Epoch 00011: val_loss did not improve from 0.56710\n",
            "141/141 [==============================] - 10s 70ms/step - loss: 0.3202 - accuracy: 0.8640 - val_loss: 0.6768 - val_accuracy: 0.7033\n",
            "Epoch 12/50\n",
            "141/141 [==============================] - ETA: 0s - loss: 0.3100 - accuracy: 0.8702\n",
            "Epoch 00012: val_loss did not improve from 0.56710\n",
            "141/141 [==============================] - 11s 76ms/step - loss: 0.3100 - accuracy: 0.8702 - val_loss: 0.6984 - val_accuracy: 0.7000\n",
            "Epoch 13/50\n",
            "141/141 [==============================] - ETA: 0s - loss: 0.2970 - accuracy: 0.8778\n",
            "Epoch 00013: val_loss did not improve from 0.56710\n",
            "141/141 [==============================] - 9s 66ms/step - loss: 0.2970 - accuracy: 0.8778 - val_loss: 0.7096 - val_accuracy: 0.6913\n",
            "Epoch 14/50\n",
            "141/141 [==============================] - ETA: 0s - loss: 0.2956 - accuracy: 0.8742\n",
            "Epoch 00014: val_loss did not improve from 0.56710\n",
            "141/141 [==============================] - 9s 66ms/step - loss: 0.2956 - accuracy: 0.8742 - val_loss: 0.7386 - val_accuracy: 0.6967\n",
            "Epoch 15/50\n",
            "141/141 [==============================] - ETA: 0s - loss: 0.2800 - accuracy: 0.8811\n",
            "Epoch 00015: val_loss did not improve from 0.56710\n",
            "141/141 [==============================] - 9s 67ms/step - loss: 0.2800 - accuracy: 0.8811 - val_loss: 0.7514 - val_accuracy: 0.6907\n",
            "Epoch 16/50\n",
            "141/141 [==============================] - ETA: 0s - loss: 0.2765 - accuracy: 0.8820\n",
            "Epoch 00016: val_loss did not improve from 0.56710\n",
            "141/141 [==============================] - 9s 66ms/step - loss: 0.2765 - accuracy: 0.8820 - val_loss: 0.7812 - val_accuracy: 0.7007\n",
            "Epoch 17/50\n",
            "141/141 [==============================] - ETA: 0s - loss: 0.2696 - accuracy: 0.8807\n",
            "Epoch 00017: val_loss did not improve from 0.56710\n",
            "141/141 [==============================] - 10s 68ms/step - loss: 0.2696 - accuracy: 0.8807 - val_loss: 0.7699 - val_accuracy: 0.6953\n",
            "Epoch 18/50\n",
            "141/141 [==============================] - ETA: 0s - loss: 0.2657 - accuracy: 0.8836\n",
            "Epoch 00018: val_loss did not improve from 0.56710\n",
            "141/141 [==============================] - 9s 66ms/step - loss: 0.2657 - accuracy: 0.8836 - val_loss: 0.7968 - val_accuracy: 0.6953\n",
            "Epoch 19/50\n",
            "141/141 [==============================] - ETA: 0s - loss: 0.2595 - accuracy: 0.8862\n",
            "Epoch 00019: val_loss did not improve from 0.56710\n",
            "141/141 [==============================] - 9s 66ms/step - loss: 0.2595 - accuracy: 0.8862 - val_loss: 0.8187 - val_accuracy: 0.6947\n",
            "Epoch 20/50\n",
            "141/141 [==============================] - ETA: 0s - loss: 0.2542 - accuracy: 0.8891\n",
            "Epoch 00020: val_loss did not improve from 0.56710\n",
            "141/141 [==============================] - 9s 67ms/step - loss: 0.2542 - accuracy: 0.8891 - val_loss: 0.8293 - val_accuracy: 0.6913\n",
            "Epoch 21/50\n",
            "141/141 [==============================] - ETA: 0s - loss: 0.2528 - accuracy: 0.8882\n",
            "Epoch 00021: val_loss did not improve from 0.56710\n",
            "141/141 [==============================] - 9s 67ms/step - loss: 0.2528 - accuracy: 0.8882 - val_loss: 0.8427 - val_accuracy: 0.6940\n",
            "Epoch 22/50\n",
            "141/141 [==============================] - ETA: 0s - loss: 0.2471 - accuracy: 0.8916\n",
            "Epoch 00022: val_loss did not improve from 0.56710\n",
            "141/141 [==============================] - 9s 65ms/step - loss: 0.2471 - accuracy: 0.8916 - val_loss: 0.8542 - val_accuracy: 0.6953\n",
            "Epoch 23/50\n",
            "141/141 [==============================] - ETA: 0s - loss: 0.2439 - accuracy: 0.8929\n",
            "Epoch 00023: val_loss did not improve from 0.56710\n",
            "141/141 [==============================] - 9s 65ms/step - loss: 0.2439 - accuracy: 0.8929 - val_loss: 0.8775 - val_accuracy: 0.7020\n",
            "Epoch 24/50\n",
            "141/141 [==============================] - ETA: 0s - loss: 0.2454 - accuracy: 0.8920\n",
            "Epoch 00024: val_loss did not improve from 0.56710\n",
            "141/141 [==============================] - 9s 67ms/step - loss: 0.2454 - accuracy: 0.8920 - val_loss: 0.8771 - val_accuracy: 0.6940\n",
            "Epoch 25/50\n",
            "141/141 [==============================] - ETA: 0s - loss: 0.2387 - accuracy: 0.8929\n",
            "Epoch 00025: val_loss did not improve from 0.56710\n",
            "141/141 [==============================] - 9s 65ms/step - loss: 0.2387 - accuracy: 0.8929 - val_loss: 0.8877 - val_accuracy: 0.7027\n",
            "Epoch 26/50\n",
            "141/141 [==============================] - ETA: 0s - loss: 0.2351 - accuracy: 0.8964\n",
            "Epoch 00026: val_loss did not improve from 0.56710\n",
            "141/141 [==============================] - 9s 66ms/step - loss: 0.2351 - accuracy: 0.8964 - val_loss: 0.9024 - val_accuracy: 0.7000\n",
            "Epoch 27/50\n",
            "141/141 [==============================] - ETA: 0s - loss: 0.2336 - accuracy: 0.8962\n",
            "Epoch 00027: val_loss did not improve from 0.56710\n",
            "141/141 [==============================] - 9s 65ms/step - loss: 0.2336 - accuracy: 0.8962 - val_loss: 0.9070 - val_accuracy: 0.7000\n",
            "Epoch 28/50\n",
            "141/141 [==============================] - ETA: 0s - loss: 0.2290 - accuracy: 0.8976\n",
            "Epoch 00028: val_loss did not improve from 0.56710\n",
            "141/141 [==============================] - 9s 65ms/step - loss: 0.2290 - accuracy: 0.8976 - val_loss: 0.9201 - val_accuracy: 0.6967\n",
            "Epoch 29/50\n",
            "141/141 [==============================] - ETA: 0s - loss: 0.2233 - accuracy: 0.9020\n",
            "Epoch 00029: val_loss did not improve from 0.56710\n",
            "141/141 [==============================] - 9s 66ms/step - loss: 0.2233 - accuracy: 0.9020 - val_loss: 0.9316 - val_accuracy: 0.6907\n",
            "Epoch 30/50\n",
            "141/141 [==============================] - ETA: 0s - loss: 0.2268 - accuracy: 0.8998\n",
            "Epoch 00030: val_loss did not improve from 0.56710\n",
            "141/141 [==============================] - 9s 65ms/step - loss: 0.2268 - accuracy: 0.8998 - val_loss: 0.9382 - val_accuracy: 0.6980\n",
            "Epoch 31/50\n",
            "141/141 [==============================] - ETA: 0s - loss: 0.2291 - accuracy: 0.8960\n",
            "Epoch 00031: val_loss did not improve from 0.56710\n",
            "141/141 [==============================] - 9s 65ms/step - loss: 0.2291 - accuracy: 0.8960 - val_loss: 0.9642 - val_accuracy: 0.7033\n",
            "Epoch 32/50\n",
            "141/141 [==============================] - ETA: 0s - loss: 0.2316 - accuracy: 0.8987\n",
            "Epoch 00032: val_loss did not improve from 0.56710\n",
            "141/141 [==============================] - 9s 66ms/step - loss: 0.2316 - accuracy: 0.8987 - val_loss: 0.9489 - val_accuracy: 0.6927\n",
            "Epoch 33/50\n",
            "141/141 [==============================] - ETA: 0s - loss: 0.2288 - accuracy: 0.8956\n",
            "Epoch 00033: val_loss did not improve from 0.56710\n",
            "141/141 [==============================] - 9s 65ms/step - loss: 0.2288 - accuracy: 0.8956 - val_loss: 0.9523 - val_accuracy: 0.6973\n",
            "Epoch 34/50\n",
            "141/141 [==============================] - ETA: 0s - loss: 0.2274 - accuracy: 0.8967\n",
            "Epoch 00034: val_loss did not improve from 0.56710\n",
            "141/141 [==============================] - 9s 66ms/step - loss: 0.2274 - accuracy: 0.8967 - val_loss: 0.9651 - val_accuracy: 0.6940\n",
            "Epoch 35/50\n",
            "141/141 [==============================] - ETA: 0s - loss: 0.2196 - accuracy: 0.9040\n",
            "Epoch 00035: val_loss did not improve from 0.56710\n",
            "141/141 [==============================] - 9s 65ms/step - loss: 0.2196 - accuracy: 0.9040 - val_loss: 0.9530 - val_accuracy: 0.6880\n",
            "Epoch 36/50\n",
            "141/141 [==============================] - ETA: 0s - loss: 0.2256 - accuracy: 0.8982\n",
            "Epoch 00036: val_loss did not improve from 0.56710\n",
            "141/141 [==============================] - 9s 66ms/step - loss: 0.2256 - accuracy: 0.8982 - val_loss: 0.9797 - val_accuracy: 0.6867\n",
            "Epoch 37/50\n",
            "141/141 [==============================] - ETA: 0s - loss: 0.2162 - accuracy: 0.9040\n",
            "Epoch 00037: val_loss did not improve from 0.56710\n",
            "141/141 [==============================] - 9s 66ms/step - loss: 0.2162 - accuracy: 0.9040 - val_loss: 0.9821 - val_accuracy: 0.6893\n",
            "Epoch 38/50\n",
            "141/141 [==============================] - ETA: 0s - loss: 0.2139 - accuracy: 0.9040\n",
            "Epoch 00038: val_loss did not improve from 0.56710\n",
            "141/141 [==============================] - 9s 65ms/step - loss: 0.2139 - accuracy: 0.9040 - val_loss: 1.0335 - val_accuracy: 0.6973\n",
            "Epoch 39/50\n",
            "141/141 [==============================] - ETA: 0s - loss: 0.2183 - accuracy: 0.9062\n",
            "Epoch 00039: val_loss did not improve from 0.56710\n",
            "141/141 [==============================] - 9s 65ms/step - loss: 0.2183 - accuracy: 0.9062 - val_loss: 0.9983 - val_accuracy: 0.6947\n",
            "Epoch 40/50\n",
            "141/141 [==============================] - ETA: 0s - loss: 0.2096 - accuracy: 0.9051\n",
            "Epoch 00040: val_loss did not improve from 0.56710\n",
            "141/141 [==============================] - 9s 66ms/step - loss: 0.2096 - accuracy: 0.9051 - val_loss: 1.0296 - val_accuracy: 0.6907\n",
            "Epoch 41/50\n",
            "141/141 [==============================] - ETA: 0s - loss: 0.2129 - accuracy: 0.9060\n",
            "Epoch 00041: val_loss did not improve from 0.56710\n",
            "141/141 [==============================] - 9s 66ms/step - loss: 0.2129 - accuracy: 0.9060 - val_loss: 1.0381 - val_accuracy: 0.6953\n",
            "Epoch 42/50\n",
            "141/141 [==============================] - ETA: 0s - loss: 0.2139 - accuracy: 0.9011\n",
            "Epoch 00042: val_loss did not improve from 0.56710\n",
            "141/141 [==============================] - 9s 65ms/step - loss: 0.2139 - accuracy: 0.9011 - val_loss: 1.0247 - val_accuracy: 0.6900\n",
            "Epoch 43/50\n",
            "141/141 [==============================] - ETA: 0s - loss: 0.2118 - accuracy: 0.9033\n",
            "Epoch 00043: val_loss did not improve from 0.56710\n",
            "141/141 [==============================] - 9s 65ms/step - loss: 0.2118 - accuracy: 0.9033 - val_loss: 1.0403 - val_accuracy: 0.6893\n",
            "Epoch 44/50\n",
            "141/141 [==============================] - ETA: 0s - loss: 0.2076 - accuracy: 0.9053\n",
            "Epoch 00044: val_loss did not improve from 0.56710\n",
            "141/141 [==============================] - 9s 66ms/step - loss: 0.2076 - accuracy: 0.9053 - val_loss: 1.0571 - val_accuracy: 0.6887\n",
            "Epoch 45/50\n",
            "141/141 [==============================] - ETA: 0s - loss: 0.2140 - accuracy: 0.9049\n",
            "Epoch 00045: val_loss did not improve from 0.56710\n",
            "141/141 [==============================] - 9s 66ms/step - loss: 0.2140 - accuracy: 0.9049 - val_loss: 1.0693 - val_accuracy: 0.6873\n",
            "Epoch 46/50\n",
            "141/141 [==============================] - ETA: 0s - loss: 0.2096 - accuracy: 0.9022\n",
            "Epoch 00046: val_loss did not improve from 0.56710\n",
            "141/141 [==============================] - 9s 67ms/step - loss: 0.2096 - accuracy: 0.9022 - val_loss: 1.0639 - val_accuracy: 0.6907\n",
            "Epoch 47/50\n",
            "141/141 [==============================] - ETA: 0s - loss: 0.2099 - accuracy: 0.9027\n",
            "Epoch 00047: val_loss did not improve from 0.56710\n",
            "141/141 [==============================] - 9s 66ms/step - loss: 0.2099 - accuracy: 0.9027 - val_loss: 1.0724 - val_accuracy: 0.6913\n",
            "Epoch 48/50\n",
            "141/141 [==============================] - ETA: 0s - loss: 0.2136 - accuracy: 0.9067\n",
            "Epoch 00048: val_loss did not improve from 0.56710\n",
            "141/141 [==============================] - 9s 66ms/step - loss: 0.2136 - accuracy: 0.9067 - val_loss: 1.0619 - val_accuracy: 0.6893\n",
            "Epoch 49/50\n",
            "141/141 [==============================] - ETA: 0s - loss: 0.2033 - accuracy: 0.9073\n",
            "Epoch 00049: val_loss did not improve from 0.56710\n",
            "141/141 [==============================] - 9s 66ms/step - loss: 0.2033 - accuracy: 0.9073 - val_loss: 1.0760 - val_accuracy: 0.6913\n",
            "Epoch 50/50\n",
            "141/141 [==============================] - ETA: 0s - loss: 0.2027 - accuracy: 0.9073\n",
            "Epoch 00050: val_loss did not improve from 0.56710\n",
            "141/141 [==============================] - 9s 64ms/step - loss: 0.2027 - accuracy: 0.9073 - val_loss: 1.0830 - val_accuracy: 0.6900\n"
          ]
        }
      ],
      "source": [
        "model4 = Sequential()\n",
        "model4.add(layers.Embedding(max_words, 40, input_length=max_len))\n",
        "model4.add(layers.LSTM(5,dropout=0.6))\n",
        "model4.add(layers.Dense(3,activation='softmax'))\n",
        "model4.compile(optimizer='adam',loss='categorical_crossentropy', metrics=['accuracy'])\n",
        "\n",
        "checkpoint4 = ModelCheckpoint(\"model4.hdf5\", monitor='val_loss', verbose=2,save_best_only=True, mode='auto', period=1,save_weights_only=False)\n",
        "history = model4.fit(X_train, y_train, epochs=50,validation_data=(X_test, y_test),callbacks=[checkpoint4])"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "fBKnMxOlCcwp",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "6088bdef-af82-4120-d145-e823560482da"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Model: \"sequential_4\"\n",
            "_________________________________________________________________\n",
            " Layer (type)                Output Shape              Param #   \n",
            "=================================================================\n",
            " embedding_4 (Embedding)     (None, 200, 40)           200000    \n",
            "                                                                 \n",
            " lstm_4 (LSTM)               (None, 5)                 920       \n",
            "                                                                 \n",
            " dense_4 (Dense)             (None, 3)                 18        \n",
            "                                                                 \n",
            "=================================================================\n",
            "Total params: 200,938\n",
            "Trainable params: 200,938\n",
            "Non-trainable params: 0\n",
            "_________________________________________________________________\n"
          ]
        }
      ],
      "source": [
        "model4.summary()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "qDjBS-cMCcwp"
      },
      "outputs": [],
      "source": [
        "best_model_4 = keras.models.load_model(\"model4.hdf5\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "0z4hS_mpCcwp",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "c66d3f3d-403f-4817-8dc6-baed6317491d"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "47/47 - 0s - loss: 0.5578 - accuracy: 0.7200 - 457ms/epoch - 10ms/step\n"
          ]
        }
      ],
      "source": [
        "test_loss, test_acc = best_model_2.evaluate(X_test, y_test, verbose=2)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "lcmBKUV6Ccwp"
      },
      "outputs": [],
      "source": [
        "predictions4 = best_model_4.predict(X_test)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "7f6e8437-93ea-4022-f821-adf4bbf1b383",
        "id": "Ki5Xu50Af70d"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[[375 285]\n",
            " [125 715]]\n"
          ]
        }
      ],
      "source": [
        "from sklearn.metrics import confusion_matrix\n",
        "matrix = confusion_matrix(y_test.argmax(axis=1), np.around(predictions4.argmax(axis=1)))\n",
        "print(matrix)"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "from sklearn.metrics import precision_recall_fscore_support as eval"
      ],
      "metadata": {
        "id": "teJ4N4i4f70d"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "precision, recall, fscore, support = eval(y_test.argmax(axis=1), predictions4.argmax(axis=1))\n",
        "print('precision (Negative, Positive):', precision)\n",
        "print('recall (Negative, Positive):', recall)\n",
        "print('fscore (Negative, Positive):', fscore)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "5a160ea6-4829-4af5-9f00-5054c5aca3a9",
        "id": "aqrVPwMrf70d"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "precision (Negative, Positive): [0.75  0.715]\n",
            "recall (Negative, Positive): [0.56818182 0.85119048]\n",
            "fscore (Negative, Positive): [0.64655172 0.77717391]\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "t_vTpMdYCdVo"
      },
      "source": [
        "# Model 2-2"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "_nPUh-R3CdVo",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "5c3a420b-067f-4114-bdf1-0c8e171e7f63"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "WARNING:tensorflow:`period` argument is deprecated. Please use `save_freq` to specify the frequency in number of batches seen.\n",
            "Epoch 1/50\n",
            "141/141 [==============================] - ETA: 0s - loss: 0.7996 - accuracy: 0.5800\n",
            "Epoch 00001: val_loss improved from inf to 0.64803, saving model to model5.hdf5\n",
            "141/141 [==============================] - 11s 68ms/step - loss: 0.7996 - accuracy: 0.5800 - val_loss: 0.6480 - val_accuracy: 0.6500\n",
            "Epoch 2/50\n",
            "141/141 [==============================] - ETA: 0s - loss: 0.6266 - accuracy: 0.6669\n",
            "Epoch 00002: val_loss improved from 0.64803 to 0.58927, saving model to model5.hdf5\n",
            "141/141 [==============================] - 9s 66ms/step - loss: 0.6266 - accuracy: 0.6669 - val_loss: 0.5893 - val_accuracy: 0.7113\n",
            "Epoch 3/50\n",
            "141/141 [==============================] - ETA: 0s - loss: 0.5592 - accuracy: 0.7296\n",
            "Epoch 00003: val_loss improved from 0.58927 to 0.56913, saving model to model5.hdf5\n",
            "141/141 [==============================] - 9s 66ms/step - loss: 0.5592 - accuracy: 0.7296 - val_loss: 0.5691 - val_accuracy: 0.7107\n",
            "Epoch 4/50\n",
            "141/141 [==============================] - ETA: 0s - loss: 0.5043 - accuracy: 0.7669\n",
            "Epoch 00004: val_loss improved from 0.56913 to 0.55503, saving model to model5.hdf5\n",
            "141/141 [==============================] - 9s 67ms/step - loss: 0.5043 - accuracy: 0.7669 - val_loss: 0.5550 - val_accuracy: 0.7287\n",
            "Epoch 5/50\n",
            "141/141 [==============================] - ETA: 0s - loss: 0.4528 - accuracy: 0.7967\n",
            "Epoch 00005: val_loss did not improve from 0.55503\n",
            "141/141 [==============================] - 9s 66ms/step - loss: 0.4528 - accuracy: 0.7967 - val_loss: 0.5745 - val_accuracy: 0.7220\n",
            "Epoch 6/50\n",
            "141/141 [==============================] - ETA: 0s - loss: 0.4161 - accuracy: 0.8207\n",
            "Epoch 00006: val_loss did not improve from 0.55503\n",
            "141/141 [==============================] - 10s 69ms/step - loss: 0.4161 - accuracy: 0.8207 - val_loss: 0.5769 - val_accuracy: 0.7227\n",
            "Epoch 7/50\n",
            "141/141 [==============================] - ETA: 0s - loss: 0.3900 - accuracy: 0.8298\n",
            "Epoch 00007: val_loss did not improve from 0.55503\n",
            "141/141 [==============================] - 9s 66ms/step - loss: 0.3900 - accuracy: 0.8298 - val_loss: 0.6006 - val_accuracy: 0.7153\n",
            "Epoch 8/50\n",
            "141/141 [==============================] - ETA: 0s - loss: 0.3607 - accuracy: 0.8491\n",
            "Epoch 00008: val_loss did not improve from 0.55503\n",
            "141/141 [==============================] - 9s 67ms/step - loss: 0.3607 - accuracy: 0.8491 - val_loss: 0.6283 - val_accuracy: 0.7100\n",
            "Epoch 9/50\n",
            "141/141 [==============================] - ETA: 0s - loss: 0.3469 - accuracy: 0.8473\n",
            "Epoch 00009: val_loss did not improve from 0.55503\n",
            "141/141 [==============================] - 9s 67ms/step - loss: 0.3469 - accuracy: 0.8473 - val_loss: 0.6444 - val_accuracy: 0.7033\n",
            "Epoch 10/50\n",
            "141/141 [==============================] - ETA: 0s - loss: 0.3281 - accuracy: 0.8576\n",
            "Epoch 00010: val_loss did not improve from 0.55503\n",
            "141/141 [==============================] - 9s 66ms/step - loss: 0.3281 - accuracy: 0.8576 - val_loss: 0.6718 - val_accuracy: 0.7080\n",
            "Epoch 11/50\n",
            "141/141 [==============================] - ETA: 0s - loss: 0.3151 - accuracy: 0.8653\n",
            "Epoch 00011: val_loss did not improve from 0.55503\n",
            "141/141 [==============================] - 9s 66ms/step - loss: 0.3151 - accuracy: 0.8653 - val_loss: 0.6901 - val_accuracy: 0.7000\n",
            "Epoch 12/50\n",
            "141/141 [==============================] - ETA: 0s - loss: 0.3063 - accuracy: 0.8662\n",
            "Epoch 00012: val_loss did not improve from 0.55503\n",
            "141/141 [==============================] - 9s 67ms/step - loss: 0.3063 - accuracy: 0.8662 - val_loss: 0.7338 - val_accuracy: 0.7040\n",
            "Epoch 13/50\n",
            "141/141 [==============================] - ETA: 0s - loss: 0.2982 - accuracy: 0.8720\n",
            "Epoch 00013: val_loss did not improve from 0.55503\n",
            "141/141 [==============================] - 10s 68ms/step - loss: 0.2982 - accuracy: 0.8720 - val_loss: 0.7237 - val_accuracy: 0.6987\n",
            "Epoch 14/50\n",
            "141/141 [==============================] - ETA: 0s - loss: 0.2857 - accuracy: 0.8813\n",
            "Epoch 00014: val_loss did not improve from 0.55503\n",
            "141/141 [==============================] - 10s 68ms/step - loss: 0.2857 - accuracy: 0.8813 - val_loss: 0.7477 - val_accuracy: 0.6980\n",
            "Epoch 15/50\n",
            "141/141 [==============================] - ETA: 0s - loss: 0.2820 - accuracy: 0.8769\n",
            "Epoch 00015: val_loss did not improve from 0.55503\n",
            "141/141 [==============================] - 10s 69ms/step - loss: 0.2820 - accuracy: 0.8769 - val_loss: 0.7667 - val_accuracy: 0.6987\n",
            "Epoch 16/50\n",
            "141/141 [==============================] - ETA: 0s - loss: 0.2729 - accuracy: 0.8860\n",
            "Epoch 00016: val_loss did not improve from 0.55503\n",
            "141/141 [==============================] - 10s 69ms/step - loss: 0.2729 - accuracy: 0.8860 - val_loss: 0.7866 - val_accuracy: 0.6887\n",
            "Epoch 17/50\n",
            "141/141 [==============================] - ETA: 0s - loss: 0.2636 - accuracy: 0.8880\n",
            "Epoch 00017: val_loss did not improve from 0.55503\n",
            "141/141 [==============================] - 17s 118ms/step - loss: 0.2636 - accuracy: 0.8880 - val_loss: 0.7805 - val_accuracy: 0.6967\n",
            "Epoch 18/50\n",
            "141/141 [==============================] - ETA: 0s - loss: 0.2632 - accuracy: 0.8869\n",
            "Epoch 00018: val_loss did not improve from 0.55503\n",
            "141/141 [==============================] - 14s 96ms/step - loss: 0.2632 - accuracy: 0.8869 - val_loss: 0.7978 - val_accuracy: 0.7020\n",
            "Epoch 19/50\n",
            "141/141 [==============================] - ETA: 0s - loss: 0.2597 - accuracy: 0.8882\n",
            "Epoch 00019: val_loss did not improve from 0.55503\n",
            "141/141 [==============================] - 9s 67ms/step - loss: 0.2597 - accuracy: 0.8882 - val_loss: 0.8106 - val_accuracy: 0.6933\n",
            "Epoch 20/50\n",
            "141/141 [==============================] - ETA: 0s - loss: 0.2493 - accuracy: 0.8909\n",
            "Epoch 00020: val_loss did not improve from 0.55503\n",
            "141/141 [==============================] - 10s 70ms/step - loss: 0.2493 - accuracy: 0.8909 - val_loss: 0.8258 - val_accuracy: 0.6967\n",
            "Epoch 21/50\n",
            "141/141 [==============================] - ETA: 0s - loss: 0.2532 - accuracy: 0.8878\n",
            "Epoch 00021: val_loss did not improve from 0.55503\n",
            "141/141 [==============================] - 10s 70ms/step - loss: 0.2532 - accuracy: 0.8878 - val_loss: 0.8384 - val_accuracy: 0.7000\n",
            "Epoch 22/50\n",
            "141/141 [==============================] - ETA: 0s - loss: 0.2498 - accuracy: 0.8898\n",
            "Epoch 00022: val_loss did not improve from 0.55503\n",
            "141/141 [==============================] - 10s 72ms/step - loss: 0.2498 - accuracy: 0.8898 - val_loss: 0.8280 - val_accuracy: 0.6900\n",
            "Epoch 23/50\n",
            "141/141 [==============================] - ETA: 0s - loss: 0.2448 - accuracy: 0.8987\n",
            "Epoch 00023: val_loss did not improve from 0.55503\n",
            "141/141 [==============================] - 10s 69ms/step - loss: 0.2448 - accuracy: 0.8987 - val_loss: 0.8664 - val_accuracy: 0.6973\n",
            "Epoch 24/50\n",
            "141/141 [==============================] - ETA: 0s - loss: 0.2414 - accuracy: 0.8929\n",
            "Epoch 00024: val_loss did not improve from 0.55503\n",
            "141/141 [==============================] - 10s 68ms/step - loss: 0.2414 - accuracy: 0.8929 - val_loss: 0.8734 - val_accuracy: 0.6933\n",
            "Epoch 25/50\n",
            "141/141 [==============================] - ETA: 0s - loss: 0.2398 - accuracy: 0.8916\n",
            "Epoch 00025: val_loss did not improve from 0.55503\n",
            "141/141 [==============================] - 10s 68ms/step - loss: 0.2398 - accuracy: 0.8916 - val_loss: 0.8911 - val_accuracy: 0.6913\n",
            "Epoch 26/50\n",
            "141/141 [==============================] - ETA: 0s - loss: 0.2380 - accuracy: 0.8984\n",
            "Epoch 00026: val_loss did not improve from 0.55503\n",
            "141/141 [==============================] - 9s 67ms/step - loss: 0.2380 - accuracy: 0.8984 - val_loss: 0.9067 - val_accuracy: 0.6880\n",
            "Epoch 27/50\n",
            "141/141 [==============================] - ETA: 0s - loss: 0.2301 - accuracy: 0.8969\n",
            "Epoch 00027: val_loss did not improve from 0.55503\n",
            "141/141 [==============================] - 9s 67ms/step - loss: 0.2301 - accuracy: 0.8969 - val_loss: 0.9109 - val_accuracy: 0.6933\n",
            "Epoch 28/50\n",
            "141/141 [==============================] - ETA: 0s - loss: 0.2397 - accuracy: 0.8902\n",
            "Epoch 00028: val_loss did not improve from 0.55503\n",
            "141/141 [==============================] - 10s 69ms/step - loss: 0.2397 - accuracy: 0.8902 - val_loss: 0.9208 - val_accuracy: 0.6893\n",
            "Epoch 29/50\n",
            "141/141 [==============================] - ETA: 0s - loss: 0.2266 - accuracy: 0.8953\n",
            "Epoch 00029: val_loss did not improve from 0.55503\n",
            "141/141 [==============================] - 12s 82ms/step - loss: 0.2266 - accuracy: 0.8953 - val_loss: 0.9352 - val_accuracy: 0.6940\n",
            "Epoch 30/50\n",
            "141/141 [==============================] - ETA: 0s - loss: 0.2213 - accuracy: 0.9007\n",
            "Epoch 00030: val_loss did not improve from 0.55503\n",
            "141/141 [==============================] - 10s 69ms/step - loss: 0.2213 - accuracy: 0.9007 - val_loss: 0.9737 - val_accuracy: 0.6893\n",
            "Epoch 31/50\n",
            "141/141 [==============================] - ETA: 0s - loss: 0.2139 - accuracy: 0.9049\n",
            "Epoch 00031: val_loss did not improve from 0.55503\n",
            "141/141 [==============================] - 10s 68ms/step - loss: 0.2139 - accuracy: 0.9049 - val_loss: 0.9486 - val_accuracy: 0.6960\n",
            "Epoch 32/50\n",
            "141/141 [==============================] - ETA: 0s - loss: 0.2154 - accuracy: 0.9038\n",
            "Epoch 00032: val_loss did not improve from 0.55503\n",
            "141/141 [==============================] - 10s 70ms/step - loss: 0.2154 - accuracy: 0.9038 - val_loss: 0.9835 - val_accuracy: 0.6940\n",
            "Epoch 33/50\n",
            "141/141 [==============================] - ETA: 0s - loss: 0.2185 - accuracy: 0.8987\n",
            "Epoch 00033: val_loss did not improve from 0.55503\n",
            "141/141 [==============================] - 10s 69ms/step - loss: 0.2185 - accuracy: 0.8987 - val_loss: 0.9772 - val_accuracy: 0.6913\n",
            "Epoch 34/50\n",
            "141/141 [==============================] - ETA: 0s - loss: 0.2132 - accuracy: 0.9089\n",
            "Epoch 00034: val_loss did not improve from 0.55503\n",
            "141/141 [==============================] - 10s 68ms/step - loss: 0.2132 - accuracy: 0.9089 - val_loss: 1.0015 - val_accuracy: 0.6860\n",
            "Epoch 35/50\n",
            "141/141 [==============================] - ETA: 0s - loss: 0.2185 - accuracy: 0.9018\n",
            "Epoch 00035: val_loss did not improve from 0.55503\n",
            "141/141 [==============================] - 10s 69ms/step - loss: 0.2185 - accuracy: 0.9018 - val_loss: 1.0135 - val_accuracy: 0.6933\n",
            "Epoch 36/50\n",
            "141/141 [==============================] - ETA: 0s - loss: 0.2135 - accuracy: 0.9062\n",
            "Epoch 00036: val_loss did not improve from 0.55503\n",
            "141/141 [==============================] - 10s 69ms/step - loss: 0.2135 - accuracy: 0.9062 - val_loss: 1.0242 - val_accuracy: 0.6867\n",
            "Epoch 37/50\n",
            "141/141 [==============================] - ETA: 0s - loss: 0.2152 - accuracy: 0.9031\n",
            "Epoch 00037: val_loss did not improve from 0.55503\n",
            "141/141 [==============================] - 10s 69ms/step - loss: 0.2152 - accuracy: 0.9031 - val_loss: 1.0563 - val_accuracy: 0.6913\n",
            "Epoch 38/50\n",
            "141/141 [==============================] - ETA: 0s - loss: 0.2105 - accuracy: 0.9047\n",
            "Epoch 00038: val_loss did not improve from 0.55503\n",
            "141/141 [==============================] - 10s 69ms/step - loss: 0.2105 - accuracy: 0.9047 - val_loss: 1.0378 - val_accuracy: 0.6760\n",
            "Epoch 39/50\n",
            "141/141 [==============================] - ETA: 0s - loss: 0.2060 - accuracy: 0.9084\n",
            "Epoch 00039: val_loss did not improve from 0.55503\n",
            "141/141 [==============================] - 10s 70ms/step - loss: 0.2060 - accuracy: 0.9084 - val_loss: 1.0527 - val_accuracy: 0.6867\n",
            "Epoch 40/50\n",
            "141/141 [==============================] - ETA: 0s - loss: 0.2077 - accuracy: 0.9029\n",
            "Epoch 00040: val_loss did not improve from 0.55503\n",
            "141/141 [==============================] - 10s 68ms/step - loss: 0.2077 - accuracy: 0.9029 - val_loss: 1.0267 - val_accuracy: 0.6853\n",
            "Epoch 41/50\n",
            "141/141 [==============================] - ETA: 0s - loss: 0.2069 - accuracy: 0.9064\n",
            "Epoch 00041: val_loss did not improve from 0.55503\n",
            "141/141 [==============================] - 10s 68ms/step - loss: 0.2069 - accuracy: 0.9064 - val_loss: 1.0547 - val_accuracy: 0.6913\n",
            "Epoch 42/50\n",
            "141/141 [==============================] - ETA: 0s - loss: 0.2064 - accuracy: 0.9042\n",
            "Epoch 00042: val_loss did not improve from 0.55503\n",
            "141/141 [==============================] - 10s 69ms/step - loss: 0.2064 - accuracy: 0.9042 - val_loss: 1.0672 - val_accuracy: 0.6867\n",
            "Epoch 43/50\n",
            "141/141 [==============================] - ETA: 0s - loss: 0.2063 - accuracy: 0.9076\n",
            "Epoch 00043: val_loss did not improve from 0.55503\n",
            "141/141 [==============================] - 10s 68ms/step - loss: 0.2063 - accuracy: 0.9076 - val_loss: 1.0687 - val_accuracy: 0.6827\n",
            "Epoch 44/50\n",
            "141/141 [==============================] - ETA: 0s - loss: 0.2022 - accuracy: 0.9093\n",
            "Epoch 00044: val_loss did not improve from 0.55503\n",
            "141/141 [==============================] - 10s 69ms/step - loss: 0.2022 - accuracy: 0.9093 - val_loss: 1.0860 - val_accuracy: 0.6813\n",
            "Epoch 45/50\n",
            "141/141 [==============================] - ETA: 0s - loss: 0.1980 - accuracy: 0.9071\n",
            "Epoch 00045: val_loss did not improve from 0.55503\n",
            "141/141 [==============================] - 10s 69ms/step - loss: 0.1980 - accuracy: 0.9071 - val_loss: 1.0949 - val_accuracy: 0.6773\n",
            "Epoch 46/50\n",
            "141/141 [==============================] - ETA: 0s - loss: 0.2002 - accuracy: 0.9051\n",
            "Epoch 00046: val_loss did not improve from 0.55503\n",
            "141/141 [==============================] - 10s 69ms/step - loss: 0.2002 - accuracy: 0.9051 - val_loss: 1.0646 - val_accuracy: 0.6953\n",
            "Epoch 47/50\n",
            "141/141 [==============================] - ETA: 0s - loss: 0.2007 - accuracy: 0.9073\n",
            "Epoch 00047: val_loss did not improve from 0.55503\n",
            "141/141 [==============================] - 10s 70ms/step - loss: 0.2007 - accuracy: 0.9073 - val_loss: 1.0905 - val_accuracy: 0.6773\n",
            "Epoch 48/50\n",
            "141/141 [==============================] - ETA: 0s - loss: 0.1952 - accuracy: 0.9096\n",
            "Epoch 00048: val_loss did not improve from 0.55503\n",
            "141/141 [==============================] - 10s 71ms/step - loss: 0.1952 - accuracy: 0.9096 - val_loss: 1.1163 - val_accuracy: 0.6780\n",
            "Epoch 49/50\n",
            "141/141 [==============================] - ETA: 0s - loss: 0.1969 - accuracy: 0.9118\n",
            "Epoch 00049: val_loss did not improve from 0.55503\n",
            "141/141 [==============================] - 10s 69ms/step - loss: 0.1969 - accuracy: 0.9118 - val_loss: 1.1206 - val_accuracy: 0.6820\n",
            "Epoch 50/50\n",
            "141/141 [==============================] - ETA: 0s - loss: 0.2015 - accuracy: 0.9093\n",
            "Epoch 00050: val_loss did not improve from 0.55503\n",
            "141/141 [==============================] - 10s 69ms/step - loss: 0.2015 - accuracy: 0.9093 - val_loss: 1.1143 - val_accuracy: 0.6820\n"
          ]
        }
      ],
      "source": [
        "model5 = Sequential()\n",
        "model5.add(layers.Embedding(max_words, 40, input_length=max_len))\n",
        "model5.add(layers.LSTM(10,dropout=0.6))\n",
        "model5.add(layers.Dense(3,activation='softmax'))\n",
        "model5.compile(optimizer='adam',loss='categorical_crossentropy', metrics=['accuracy'])\n",
        "\n",
        "checkpoint5 = ModelCheckpoint(\"model5.hdf5\", monitor='val_loss', verbose=2,save_best_only=True, mode='auto', period=1,save_weights_only=False)\n",
        "history = model5.fit(X_train, y_train, epochs=50,validation_data=(X_test, y_test),callbacks=[checkpoint5])"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "-XV3_CRHCdVo",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "552ebd4f-83ae-45fb-cc8b-7246e8bff234"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Model: \"sequential_5\"\n",
            "_________________________________________________________________\n",
            " Layer (type)                Output Shape              Param #   \n",
            "=================================================================\n",
            " embedding_5 (Embedding)     (None, 200, 40)           200000    \n",
            "                                                                 \n",
            " lstm_5 (LSTM)               (None, 10)                2040      \n",
            "                                                                 \n",
            " dense_5 (Dense)             (None, 3)                 33        \n",
            "                                                                 \n",
            "=================================================================\n",
            "Total params: 202,073\n",
            "Trainable params: 202,073\n",
            "Non-trainable params: 0\n",
            "_________________________________________________________________\n"
          ]
        }
      ],
      "source": [
        "model5.summary()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "r2MHQ2MDCdVo"
      },
      "outputs": [],
      "source": [
        "best_model_5 = keras.models.load_model(\"model5.hdf5\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "g3ce-zXaCdVp",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "9ada2a30-e3bf-47b1-b138-cd0eec55a19f"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "47/47 - 1s - loss: 0.5550 - accuracy: 0.7287 - 924ms/epoch - 20ms/step\n"
          ]
        }
      ],
      "source": [
        "test_loss, test_acc = best_model_5.evaluate(X_test, y_test, verbose=2)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "DScbXVklCdVp"
      },
      "outputs": [],
      "source": [
        "predictions5 = best_model_5.predict(X_test)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "2de8742f-05f0-4463-8b58-6e0dee65e37b",
        "id": "3LAGTbQMgEg1"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[[402 258]\n",
            " [149 691]]\n"
          ]
        }
      ],
      "source": [
        "from sklearn.metrics import confusion_matrix\n",
        "matrix = confusion_matrix(y_test.argmax(axis=1), np.around(predictions5.argmax(axis=1)))\n",
        "print(matrix)  #tn = 398,fp = 262,fn = 147,tp = 693 "
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "from sklearn.metrics import precision_recall_fscore_support as eval"
      ],
      "metadata": {
        "id": "ZXLCCzHBgEg2"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "precision, recall, fscore, support = eval(y_test.argmax(axis=1), predictions5.argmax(axis=1))\n",
        "print('precision (Negative, Positive):', precision)\n",
        "print('recall (Negative, Positive):', recall)\n",
        "print('fscore (Negative, Positive):', fscore)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "373ef2a2-7399-48d6-d99d-66a1d2ee4d51",
        "id": "sq8BlldhgEg2"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "precision (Negative, Positive): [0.72958258 0.72813488]\n",
            "recall (Negative, Positive): [0.60909091 0.82261905]\n",
            "fscore (Negative, Positive): [0.66391412 0.7724986 ]\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "sEpAqaULgIyk"
      },
      "source": [
        "# Model 3-2"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "f92186d3-f834-45b3-daaf-e8fc002f63ce",
        "id": "KBGycf_ogIyk"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "WARNING:tensorflow:`period` argument is deprecated. Please use `save_freq` to specify the frequency in number of batches seen.\n",
            "Epoch 1/50\n",
            "141/141 [==============================] - ETA: 0s - loss: 0.7587 - accuracy: 0.5949\n",
            "Epoch 00001: val_loss improved from inf to 0.63192, saving model to model5.hdf5\n",
            "141/141 [==============================] - 12s 75ms/step - loss: 0.7587 - accuracy: 0.5949 - val_loss: 0.6319 - val_accuracy: 0.6613\n",
            "Epoch 2/50\n",
            "141/141 [==============================] - ETA: 0s - loss: 0.6105 - accuracy: 0.6791\n",
            "Epoch 00002: val_loss improved from 0.63192 to 0.58587, saving model to model5.hdf5\n",
            "141/141 [==============================] - 10s 71ms/step - loss: 0.6105 - accuracy: 0.6791 - val_loss: 0.5859 - val_accuracy: 0.7213\n",
            "Epoch 3/50\n",
            "141/141 [==============================] - ETA: 0s - loss: 0.5388 - accuracy: 0.7387\n",
            "Epoch 00003: val_loss improved from 0.58587 to 0.56729, saving model to model5.hdf5\n",
            "141/141 [==============================] - 10s 71ms/step - loss: 0.5388 - accuracy: 0.7387 - val_loss: 0.5673 - val_accuracy: 0.7293\n",
            "Epoch 4/50\n",
            "141/141 [==============================] - ETA: 0s - loss: 0.4831 - accuracy: 0.7764\n",
            "Epoch 00004: val_loss improved from 0.56729 to 0.56593, saving model to model5.hdf5\n",
            "141/141 [==============================] - 10s 71ms/step - loss: 0.4831 - accuracy: 0.7764 - val_loss: 0.5659 - val_accuracy: 0.7233\n",
            "Epoch 5/50\n",
            "141/141 [==============================] - ETA: 0s - loss: 0.4250 - accuracy: 0.8091\n",
            "Epoch 00005: val_loss did not improve from 0.56593\n",
            "141/141 [==============================] - 10s 70ms/step - loss: 0.4250 - accuracy: 0.8091 - val_loss: 0.5728 - val_accuracy: 0.7293\n",
            "Epoch 6/50\n",
            "141/141 [==============================] - ETA: 0s - loss: 0.3901 - accuracy: 0.8333\n",
            "Epoch 00006: val_loss did not improve from 0.56593\n",
            "141/141 [==============================] - 10s 70ms/step - loss: 0.3901 - accuracy: 0.8333 - val_loss: 0.5998 - val_accuracy: 0.7160\n",
            "Epoch 7/50\n",
            "141/141 [==============================] - ETA: 0s - loss: 0.3645 - accuracy: 0.8429\n",
            "Epoch 00007: val_loss did not improve from 0.56593\n",
            "141/141 [==============================] - 10s 71ms/step - loss: 0.3645 - accuracy: 0.8429 - val_loss: 0.6328 - val_accuracy: 0.7193\n",
            "Epoch 8/50\n",
            "141/141 [==============================] - ETA: 0s - loss: 0.3422 - accuracy: 0.8540\n",
            "Epoch 00008: val_loss did not improve from 0.56593\n",
            "141/141 [==============================] - 10s 71ms/step - loss: 0.3422 - accuracy: 0.8540 - val_loss: 0.6444 - val_accuracy: 0.7093\n",
            "Epoch 9/50\n",
            "141/141 [==============================] - ETA: 0s - loss: 0.3199 - accuracy: 0.8676\n",
            "Epoch 00009: val_loss did not improve from 0.56593\n",
            "141/141 [==============================] - 10s 70ms/step - loss: 0.3199 - accuracy: 0.8676 - val_loss: 0.6555 - val_accuracy: 0.7047\n",
            "Epoch 10/50\n",
            "141/141 [==============================] - ETA: 0s - loss: 0.3078 - accuracy: 0.8684\n",
            "Epoch 00010: val_loss did not improve from 0.56593\n",
            "141/141 [==============================] - 10s 71ms/step - loss: 0.3078 - accuracy: 0.8684 - val_loss: 0.7056 - val_accuracy: 0.6987\n",
            "Epoch 11/50\n",
            "141/141 [==============================] - ETA: 0s - loss: 0.3019 - accuracy: 0.8727\n",
            "Epoch 00011: val_loss did not improve from 0.56593\n",
            "141/141 [==============================] - 10s 70ms/step - loss: 0.3019 - accuracy: 0.8727 - val_loss: 0.7064 - val_accuracy: 0.6973\n",
            "Epoch 12/50\n",
            "141/141 [==============================] - ETA: 0s - loss: 0.2830 - accuracy: 0.8796\n",
            "Epoch 00012: val_loss did not improve from 0.56593\n",
            "141/141 [==============================] - 10s 70ms/step - loss: 0.2830 - accuracy: 0.8796 - val_loss: 0.7448 - val_accuracy: 0.6973\n",
            "Epoch 13/50\n",
            "141/141 [==============================] - ETA: 0s - loss: 0.2762 - accuracy: 0.8842\n",
            "Epoch 00013: val_loss did not improve from 0.56593\n",
            "141/141 [==============================] - 10s 71ms/step - loss: 0.2762 - accuracy: 0.8842 - val_loss: 0.7793 - val_accuracy: 0.6893\n",
            "Epoch 14/50\n",
            "141/141 [==============================] - ETA: 0s - loss: 0.2669 - accuracy: 0.8896\n",
            "Epoch 00014: val_loss did not improve from 0.56593\n",
            "141/141 [==============================] - 10s 72ms/step - loss: 0.2669 - accuracy: 0.8896 - val_loss: 0.7663 - val_accuracy: 0.6960\n",
            "Epoch 15/50\n",
            "141/141 [==============================] - ETA: 0s - loss: 0.2624 - accuracy: 0.8904\n",
            "Epoch 00015: val_loss did not improve from 0.56593\n",
            "141/141 [==============================] - 10s 71ms/step - loss: 0.2624 - accuracy: 0.8904 - val_loss: 0.7586 - val_accuracy: 0.6887\n",
            "Epoch 16/50\n",
            "141/141 [==============================] - ETA: 0s - loss: 0.2602 - accuracy: 0.8916\n",
            "Epoch 00016: val_loss did not improve from 0.56593\n",
            "141/141 [==============================] - 10s 71ms/step - loss: 0.2602 - accuracy: 0.8916 - val_loss: 0.8096 - val_accuracy: 0.6960\n",
            "Epoch 17/50\n",
            "141/141 [==============================] - ETA: 0s - loss: 0.2511 - accuracy: 0.8942\n",
            "Epoch 00017: val_loss did not improve from 0.56593\n",
            "141/141 [==============================] - 10s 71ms/step - loss: 0.2511 - accuracy: 0.8942 - val_loss: 0.8281 - val_accuracy: 0.6887\n",
            "Epoch 18/50\n",
            "141/141 [==============================] - ETA: 0s - loss: 0.2450 - accuracy: 0.8911\n",
            "Epoch 00018: val_loss did not improve from 0.56593\n",
            "141/141 [==============================] - 10s 71ms/step - loss: 0.2450 - accuracy: 0.8911 - val_loss: 0.8084 - val_accuracy: 0.6867\n",
            "Epoch 19/50\n",
            "141/141 [==============================] - ETA: 0s - loss: 0.2413 - accuracy: 0.8969\n",
            "Epoch 00019: val_loss did not improve from 0.56593\n",
            "141/141 [==============================] - 10s 72ms/step - loss: 0.2413 - accuracy: 0.8969 - val_loss: 0.8256 - val_accuracy: 0.6840\n",
            "Epoch 20/50\n",
            "141/141 [==============================] - ETA: 0s - loss: 0.2370 - accuracy: 0.8984\n",
            "Epoch 00020: val_loss did not improve from 0.56593\n",
            "141/141 [==============================] - 10s 71ms/step - loss: 0.2370 - accuracy: 0.8984 - val_loss: 0.8724 - val_accuracy: 0.6933\n",
            "Epoch 21/50\n",
            "141/141 [==============================] - ETA: 0s - loss: 0.2368 - accuracy: 0.8958\n",
            "Epoch 00021: val_loss did not improve from 0.56593\n",
            "141/141 [==============================] - 10s 71ms/step - loss: 0.2368 - accuracy: 0.8958 - val_loss: 0.8414 - val_accuracy: 0.6927\n",
            "Epoch 22/50\n",
            "141/141 [==============================] - ETA: 0s - loss: 0.2344 - accuracy: 0.8962\n",
            "Epoch 00022: val_loss did not improve from 0.56593\n",
            "141/141 [==============================] - 10s 71ms/step - loss: 0.2344 - accuracy: 0.8962 - val_loss: 0.8537 - val_accuracy: 0.6920\n",
            "Epoch 23/50\n",
            "141/141 [==============================] - ETA: 0s - loss: 0.2285 - accuracy: 0.9000\n",
            "Epoch 00023: val_loss did not improve from 0.56593\n",
            "141/141 [==============================] - 10s 70ms/step - loss: 0.2285 - accuracy: 0.9000 - val_loss: 0.8870 - val_accuracy: 0.6913\n",
            "Epoch 24/50\n",
            "141/141 [==============================] - ETA: 0s - loss: 0.2261 - accuracy: 0.8996\n",
            "Epoch 00024: val_loss did not improve from 0.56593\n",
            "141/141 [==============================] - 10s 71ms/step - loss: 0.2261 - accuracy: 0.8996 - val_loss: 0.9192 - val_accuracy: 0.6927\n",
            "Epoch 25/50\n",
            "141/141 [==============================] - ETA: 0s - loss: 0.2173 - accuracy: 0.9049\n",
            "Epoch 00025: val_loss did not improve from 0.56593\n",
            "141/141 [==============================] - 10s 70ms/step - loss: 0.2173 - accuracy: 0.9049 - val_loss: 0.9209 - val_accuracy: 0.6900\n",
            "Epoch 26/50\n",
            "141/141 [==============================] - ETA: 0s - loss: 0.2154 - accuracy: 0.9022\n",
            "Epoch 00026: val_loss did not improve from 0.56593\n",
            "141/141 [==============================] - 10s 70ms/step - loss: 0.2154 - accuracy: 0.9022 - val_loss: 0.9469 - val_accuracy: 0.6927\n",
            "Epoch 27/50\n",
            "141/141 [==============================] - ETA: 0s - loss: 0.2181 - accuracy: 0.9049\n",
            "Epoch 00027: val_loss did not improve from 0.56593\n",
            "141/141 [==============================] - 10s 71ms/step - loss: 0.2181 - accuracy: 0.9049 - val_loss: 0.9337 - val_accuracy: 0.6927\n",
            "Epoch 28/50\n",
            "141/141 [==============================] - ETA: 0s - loss: 0.2212 - accuracy: 0.9024\n",
            "Epoch 00028: val_loss did not improve from 0.56593\n",
            "141/141 [==============================] - 10s 71ms/step - loss: 0.2212 - accuracy: 0.9024 - val_loss: 0.9693 - val_accuracy: 0.6980\n",
            "Epoch 29/50\n",
            "141/141 [==============================] - ETA: 0s - loss: 0.2128 - accuracy: 0.9087\n",
            "Epoch 00029: val_loss did not improve from 0.56593\n",
            "141/141 [==============================] - 10s 72ms/step - loss: 0.2128 - accuracy: 0.9087 - val_loss: 0.9583 - val_accuracy: 0.6880\n",
            "Epoch 30/50\n",
            "141/141 [==============================] - ETA: 0s - loss: 0.2094 - accuracy: 0.9082\n",
            "Epoch 00030: val_loss did not improve from 0.56593\n",
            "141/141 [==============================] - 10s 71ms/step - loss: 0.2094 - accuracy: 0.9082 - val_loss: 1.0086 - val_accuracy: 0.6920\n",
            "Epoch 31/50\n",
            "141/141 [==============================] - ETA: 0s - loss: 0.2080 - accuracy: 0.9069\n",
            "Epoch 00031: val_loss did not improve from 0.56593\n",
            "141/141 [==============================] - 11s 75ms/step - loss: 0.2080 - accuracy: 0.9069 - val_loss: 1.0235 - val_accuracy: 0.6880\n",
            "Epoch 32/50\n",
            "141/141 [==============================] - ETA: 0s - loss: 0.2018 - accuracy: 0.9116\n",
            "Epoch 00032: val_loss did not improve from 0.56593\n",
            "141/141 [==============================] - 10s 72ms/step - loss: 0.2018 - accuracy: 0.9116 - val_loss: 1.0136 - val_accuracy: 0.6820\n",
            "Epoch 33/50\n",
            "141/141 [==============================] - ETA: 0s - loss: 0.2086 - accuracy: 0.9087\n",
            "Epoch 00033: val_loss did not improve from 0.56593\n",
            "141/141 [==============================] - 10s 72ms/step - loss: 0.2086 - accuracy: 0.9087 - val_loss: 1.0347 - val_accuracy: 0.6800\n",
            "Epoch 34/50\n",
            "141/141 [==============================] - ETA: 0s - loss: 0.2005 - accuracy: 0.9111\n",
            "Epoch 00034: val_loss did not improve from 0.56593\n",
            "141/141 [==============================] - 10s 72ms/step - loss: 0.2005 - accuracy: 0.9111 - val_loss: 1.0391 - val_accuracy: 0.6880\n",
            "Epoch 35/50\n",
            "141/141 [==============================] - ETA: 0s - loss: 0.1974 - accuracy: 0.9082\n",
            "Epoch 00035: val_loss did not improve from 0.56593\n",
            "141/141 [==============================] - 10s 71ms/step - loss: 0.1974 - accuracy: 0.9082 - val_loss: 1.0401 - val_accuracy: 0.6780\n",
            "Epoch 36/50\n",
            "141/141 [==============================] - ETA: 0s - loss: 0.1983 - accuracy: 0.9073\n",
            "Epoch 00036: val_loss did not improve from 0.56593\n",
            "141/141 [==============================] - 10s 72ms/step - loss: 0.1983 - accuracy: 0.9073 - val_loss: 1.0542 - val_accuracy: 0.6827\n",
            "Epoch 37/50\n",
            "141/141 [==============================] - ETA: 0s - loss: 0.2015 - accuracy: 0.9100\n",
            "Epoch 00037: val_loss did not improve from 0.56593\n",
            "141/141 [==============================] - 10s 73ms/step - loss: 0.2015 - accuracy: 0.9100 - val_loss: 1.0759 - val_accuracy: 0.6767\n",
            "Epoch 38/50\n",
            "141/141 [==============================] - ETA: 0s - loss: 0.1986 - accuracy: 0.9118\n",
            "Epoch 00038: val_loss did not improve from 0.56593\n",
            "141/141 [==============================] - 10s 71ms/step - loss: 0.1986 - accuracy: 0.9118 - val_loss: 1.0692 - val_accuracy: 0.6773\n",
            "Epoch 39/50\n",
            "141/141 [==============================] - ETA: 0s - loss: 0.1962 - accuracy: 0.9093\n",
            "Epoch 00039: val_loss did not improve from 0.56593\n",
            "141/141 [==============================] - 10s 71ms/step - loss: 0.1962 - accuracy: 0.9093 - val_loss: 1.1068 - val_accuracy: 0.6753\n",
            "Epoch 40/50\n",
            "141/141 [==============================] - ETA: 0s - loss: 0.1975 - accuracy: 0.9096\n",
            "Epoch 00040: val_loss did not improve from 0.56593\n",
            "141/141 [==============================] - 10s 71ms/step - loss: 0.1975 - accuracy: 0.9096 - val_loss: 1.0964 - val_accuracy: 0.6747\n",
            "Epoch 41/50\n",
            "141/141 [==============================] - ETA: 0s - loss: 0.1972 - accuracy: 0.9107\n",
            "Epoch 00041: val_loss did not improve from 0.56593\n",
            "141/141 [==============================] - 10s 71ms/step - loss: 0.1972 - accuracy: 0.9107 - val_loss: 1.1155 - val_accuracy: 0.6760\n",
            "Epoch 42/50\n",
            "141/141 [==============================] - ETA: 0s - loss: 0.1970 - accuracy: 0.9113\n",
            "Epoch 00042: val_loss did not improve from 0.56593\n",
            "141/141 [==============================] - 10s 72ms/step - loss: 0.1970 - accuracy: 0.9113 - val_loss: 1.1059 - val_accuracy: 0.6727\n",
            "Epoch 43/50\n",
            "141/141 [==============================] - ETA: 0s - loss: 0.1978 - accuracy: 0.9098\n",
            "Epoch 00043: val_loss did not improve from 0.56593\n",
            "141/141 [==============================] - 10s 72ms/step - loss: 0.1978 - accuracy: 0.9098 - val_loss: 1.1643 - val_accuracy: 0.6740\n",
            "Epoch 44/50\n",
            "141/141 [==============================] - ETA: 0s - loss: 0.1956 - accuracy: 0.9100\n",
            "Epoch 00044: val_loss did not improve from 0.56593\n",
            "141/141 [==============================] - 10s 73ms/step - loss: 0.1956 - accuracy: 0.9100 - val_loss: 1.0967 - val_accuracy: 0.6713\n",
            "Epoch 45/50\n",
            "141/141 [==============================] - ETA: 0s - loss: 0.1899 - accuracy: 0.9129\n",
            "Epoch 00045: val_loss did not improve from 0.56593\n",
            "141/141 [==============================] - 10s 73ms/step - loss: 0.1899 - accuracy: 0.9129 - val_loss: 1.2038 - val_accuracy: 0.6707\n",
            "Epoch 46/50\n",
            "141/141 [==============================] - ETA: 0s - loss: 0.1925 - accuracy: 0.9136\n",
            "Epoch 00046: val_loss did not improve from 0.56593\n",
            "141/141 [==============================] - 10s 70ms/step - loss: 0.1925 - accuracy: 0.9136 - val_loss: 1.1421 - val_accuracy: 0.6707\n",
            "Epoch 47/50\n",
            "141/141 [==============================] - ETA: 0s - loss: 0.1877 - accuracy: 0.9162\n",
            "Epoch 00047: val_loss did not improve from 0.56593\n",
            "141/141 [==============================] - 10s 71ms/step - loss: 0.1877 - accuracy: 0.9162 - val_loss: 1.1501 - val_accuracy: 0.6767\n",
            "Epoch 48/50\n",
            "141/141 [==============================] - ETA: 0s - loss: 0.1874 - accuracy: 0.9142\n",
            "Epoch 00048: val_loss did not improve from 0.56593\n",
            "141/141 [==============================] - 10s 72ms/step - loss: 0.1874 - accuracy: 0.9142 - val_loss: 1.1812 - val_accuracy: 0.6660\n",
            "Epoch 49/50\n",
            "141/141 [==============================] - ETA: 0s - loss: 0.1896 - accuracy: 0.9167\n",
            "Epoch 00049: val_loss did not improve from 0.56593\n",
            "141/141 [==============================] - 10s 71ms/step - loss: 0.1896 - accuracy: 0.9167 - val_loss: 1.1702 - val_accuracy: 0.6720\n",
            "Epoch 50/50\n",
            "141/141 [==============================] - ETA: 0s - loss: 0.1884 - accuracy: 0.9160\n",
            "Epoch 00050: val_loss did not improve from 0.56593\n",
            "141/141 [==============================] - 10s 70ms/step - loss: 0.1884 - accuracy: 0.9160 - val_loss: 1.2086 - val_accuracy: 0.6647\n"
          ]
        }
      ],
      "source": [
        "model5 = Sequential()\n",
        "model5.add(layers.Embedding(max_words, 40, input_length=max_len))\n",
        "model5.add(layers.LSTM(15,dropout=0.6))\n",
        "model5.add(layers.Dense(3,activation='softmax'))\n",
        "model5.compile(optimizer='adam',loss='categorical_crossentropy', metrics=['accuracy'])\n",
        "\n",
        "checkpoint5 = ModelCheckpoint(\"model5.hdf5\", monitor='val_loss', verbose=2,save_best_only=True, mode='auto', period=1,save_weights_only=False)\n",
        "history = model5.fit(X_train, y_train, epochs=50,validation_data=(X_test, y_test),callbacks=[checkpoint5])"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "dca1c19b-613d-418e-9dda-ddb64525afee",
        "id": "JQy6TvyMgIyk"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Model: \"sequential_6\"\n",
            "_________________________________________________________________\n",
            " Layer (type)                Output Shape              Param #   \n",
            "=================================================================\n",
            " embedding_6 (Embedding)     (None, 200, 40)           200000    \n",
            "                                                                 \n",
            " lstm_6 (LSTM)               (None, 15)                3360      \n",
            "                                                                 \n",
            " dense_6 (Dense)             (None, 3)                 48        \n",
            "                                                                 \n",
            "=================================================================\n",
            "Total params: 203,408\n",
            "Trainable params: 203,408\n",
            "Non-trainable params: 0\n",
            "_________________________________________________________________\n"
          ]
        }
      ],
      "source": [
        "model5.summary()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "_JREjMJkgIyk"
      },
      "outputs": [],
      "source": [
        "best_model_5 = keras.models.load_model(\"model5.hdf5\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "4bbdd431-f2b7-409d-dc4d-ce8a2a83eebf",
        "id": "aYb5ssQCgIyk"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "47/47 - 1s - loss: 0.5659 - accuracy: 0.7233 - 897ms/epoch - 19ms/step\n"
          ]
        }
      ],
      "source": [
        "test_loss, test_acc = best_model_5.evaluate(X_test, y_test, verbose=2)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "RIBdD-AUgIyl"
      },
      "outputs": [],
      "source": [
        "predictions5 = best_model_5.predict(X_test)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "ed170bc8-58be-470a-a30b-d952264e1f5b",
        "id": "U7OYmoYBgIyl"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[[464 196]\n",
            " [219 621]]\n"
          ]
        }
      ],
      "source": [
        "from sklearn.metrics import confusion_matrix\n",
        "matrix = confusion_matrix(y_test.argmax(axis=1), np.around(predictions5.argmax(axis=1)))\n",
        "print(matrix)"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "from sklearn.metrics import precision_recall_fscore_support as eval"
      ],
      "metadata": {
        "id": "KbIXRot2gIyl"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "precision, recall, fscore, support = eval(y_test.argmax(axis=1), predictions5.argmax(axis=1))\n",
        "print('precision (Negative, Positive):', precision)\n",
        "print('recall (Negative, Positive):', recall)\n",
        "print('fscore (Negative, Positive):', fscore)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "00a96c51-2a14-45bd-cf9b-6e7354f81cb8",
        "id": "x7Bp2AODgIyl"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "precision (Negative, Positive): [0.67935578 0.76009792]\n",
            "recall (Negative, Positive): [0.7030303  0.73928571]\n",
            "fscore (Negative, Positive): [0.69099032 0.74954737]\n"
          ]
        }
      ]
    }
  ],
  "metadata": {
    "accelerator": "GPU",
    "colab": {
      "collapsed_sections": [],
      "name": "Tokopedia Sentiment Analysis.ipynb",
      "provenance": []
    },
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}